{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring model ddG accuracy on protein variants\n",
    "The goal of this notebook is to experiment with model ddG prediction capabilities, and exploring the possibility of predicting ddG of variants that were not supported previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import sys\n",
    "sys.path.append('..')    # add parent directory to path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model.hydro_net import PEM\n",
    "from model.model_cfg import CFG\n",
    "from Utils.train_utils import *\n",
    "from Utils.pdb_parser import get_pdb_data\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "# Import the model\n",
    "model = PEM(layers=CFG.num_layers,gaussian_coef=CFG.gaussian_coef).to(CFG.device)\n",
    "# Upload model weights\n",
    "CFG.model_path = '../data/Trained_models/'\n",
    "epoch = 25\n",
    "model_dict = torch.load(CFG.model_path+f\"{epoch}_final_model.pt\",map_location=CFG.device,weights_only=False)\n",
    "model.load_state_dict(model_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration\n",
    "remove_indels = True\n",
    "one_mute = True\n",
    "# Constants\n",
    "NUMBER_OF_VARIANTS = 128\n",
    "TENSOR_ROOT = r\"mutation_data\\tensors\" \n",
    "MUTATIONS_ROOT = r\"mutation_data\\mutations\"\n",
    "COORDS = 'coords_tensor.pt'\n",
    "DELTA_G = 'deltaG.pt'\n",
    "MASKS = 'mask_tensor.pt'\n",
    "ONE_HOT = 'one_hot_encodings.pt'\n",
    "PROTT5_EMBEDDINGS = 'prott5_embeddings'\n",
    "VAL_RATIO = 0.2\n",
    "RANDOM_SEED = 42\n",
    "NANO_TO_ANGSTROM = 0.1\n",
    "DEBUG = False\n",
    "TM_PATH = './data/Processed_K50_dG_datasets/TM_proteins.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with a single protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from AllProteinValidationDataset\n",
    "def load_embedding_tensor(embeddings_dir):\n",
    "    embeddings = []\n",
    "    all_embedding_files = sorted(glob.glob(os.path.join(embeddings_dir, 'prott5_embedding_*.pt')),\n",
    "                                 key=lambda x: int(os.path.splitext(x)[0].split('_')[-1]))\n",
    "\n",
    "    for filename in all_embedding_files:\n",
    "        if filename.endswith('.pt'):\n",
    "            embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n",
    "            embeddings.append(embedding_tensor)\n",
    "\n",
    "    return torch.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wt_index(mutations_data):\n",
    "    \"\"\"\n",
    "    Find the index of the wildtype sequence in the list of mutations\n",
    "    Figure out later which wt is the true wt\n",
    "    \"\"\"\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def calculate_dG(protein_graph, protein_unfolded_graph):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Gf = model(protein_graph.unsqueeze(0))\n",
    "        Gf = Gf.cpu().numpy()\n",
    "        Gf = Gf[0]\n",
    "        Gu = model(protein_unfolded_graph.unsqueeze(0))\n",
    "        Gu = Gu.cpu().numpy()\n",
    "        Gu = Gu[0]\n",
    "        pred_deltaG = Gu - Gf\n",
    "        return pred_deltaG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3969383861.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_path, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3969383861.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_path, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3969383861.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_path, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3969383861.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_path, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    }
   ],
   "source": [
    "#Data preparation\n",
    "protein_path = os.path.join(TENSOR_ROOT, '1A0N')\n",
    "mutations_path = os.path.join(MUTATIONS_ROOT, '1A0N.csv')\n",
    "\n",
    "mutations = pd.read_csv(mutations_path)\n",
    "\n",
    "if remove_indels:\n",
    "    mutations = mutations[~mutations['mut_type'].str.contains('ins|del')].reset_index(drop=True)\n",
    "    \n",
    "# Load and preprocess the data for each protein\n",
    "coords_tensor = torch.load(os.path.join(protein_path, COORDS))\n",
    "delta_g_tensor = torch.load(os.path.join(protein_path, DELTA_G))\n",
    "mask_tensor = torch.load(os.path.join(protein_path, MASKS))\n",
    "one_hot_tensor = torch.load(os.path.join(protein_path, ONE_HOT))\n",
    "embedding_tensor = load_embedding_tensor(os.path.join(protein_path, PROTT5_EMBEDDINGS))\n",
    "\n",
    "# remove the mutations with more than one mutation\n",
    "if one_mute:\n",
    "    one_mut_index = mutations[~mutations['mut_type'].str.contains(':')]\n",
    "    mutations = mutations.loc[one_mut_index.index]\n",
    "    delta_g_tensor = delta_g_tensor[one_mut_index.index]\n",
    "    one_hot_tensor = one_hot_tensor[one_mut_index.index]\n",
    "    embedding_tensor = embedding_tensor[one_mut_index.index]\n",
    "    \n",
    "mutations_data = {\n",
    "    'name': protein_path,\n",
    "    'mutations': mutations['mut_type'].to_list(),\n",
    "    'prott5': embedding_tensor,\n",
    "    'coords': coords_tensor,\n",
    "    'one_hot': one_hot_tensor,\n",
    "    'delta_g': delta_g_tensor,\n",
    "    'masks': mask_tensor\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: mutation_data\\tensors\\1A0N\n",
      "Number of mutations: 2210\n",
      "Protein T5 embeddings shape: torch.Size([2210, 58, 1024])\n",
      "Protein coords shape: torch.Size([58, 4, 3])\n",
      "Protein one hot encodings shape: torch.Size([2210, 58, 21])\n",
      "Protein delta G shape: torch.Size([2210])\n",
      "Protein masks shape: torch.Size([58])\n"
     ]
    }
   ],
   "source": [
    "#print mutation data information\n",
    "print(f\"Protein: {mutations_data['name']}\")\n",
    "print(f\"Number of mutations: {len(mutations_data['mutations'])}\")\n",
    "print(f\"Protein T5 embeddings shape: {mutations_data['prott5'].shape}\")\n",
    "print(f\"Protein coords shape: {mutations_data['coords'].shape}\")\n",
    "print(f\"Protein one hot encodings shape: {mutations_data['one_hot'].shape}\")\n",
    "print(f\"Protein delta G shape: {mutations_data['delta_g'].shape}\")\n",
    "print(f\"Protein masks shape: {mutations_data['masks'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([58, 1093])\n",
      "-1.9128189\n"
     ]
    }
   ],
   "source": [
    "#get wt folded graph\n",
    "#assuming wt is the first sequence\n",
    "wt_index = find_wt_index(mutations_data)\n",
    "\n",
    "seq_one_hot = mutations_data['one_hot'][wt_index]\n",
    "proT5_emb = mutations_data['prott5'][wt_index]\n",
    "mask = mutations_data['masks'][wt_index]\n",
    "coords_tensor = mutations_data['coords']\n",
    "protein_graph = get_graph( coords_tensor ,seq_one_hot, proT5_emb,mask)\n",
    "print(protein_graph.shape)\n",
    "#get wt unfolded graph\n",
    "protein_unfolded_graph = get_unfolded_graph( coords_tensor ,seq_one_hot, proT5_emb,mask)\n",
    "#calculate dG\n",
    "pred_wt_deltaG = calculate_dG(protein_graph, protein_unfolded_graph)\n",
    "print(pred_wt_deltaG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9128189, -1.9128189, -1.9128189, -1.9128189, -2.059597, -1.4475288, 3.6489077, 1.1425676, -0.2574787, -1.3480759, -0.39097214, -1.5175056, -1.7922173, -0.48610306, -0.74300194, -0.023918152, -2.3051147, -1.6167736, -0.79006004, -0.55924225, -1.777729, -2.0512009, -1.8434162, -1.7883263, -1.4741306, -2.4980278, -1.6094913, -1.4427719, -1.4530525, -1.7375412, -1.3019295, -2.1678772, -1.7538815, -1.8636036, -1.700676, -1.706028, -1.7485104, -2.398903, -1.4889164, -1.7892838, -0.92637825, -0.80413246, -1.4868145, -0.7943363, -1.7148018, -0.76965714, -1.8974648, -1.3092804, -1.1796398, -1.4278622, -2.1715374, -2.190075, -1.5623894, -1.6792889, -2.6545181, -2.8301697, -1.2293892, -1.2370129, -1.4861164, -1.9986649, -1.7525349, -2.5444126, -2.1364803, -1.9321976, -1.627039, -3.2045307, -2.6811638, -2.238329, -1.5813675, -2.8107643, -2.7763882, -1.6301899, -2.3790035, -2.3221645, -3.1501884, -3.0566463, -1.1757126, -2.0618057, -1.8428555, -1.3071537, -1.2411041, -1.5733128, -1.541832, -1.5656738, -1.2779484, -1.4859543, -1.2864647, -1.1869068, -1.5247326, -1.8451996, -1.7880554, -1.9142895, -1.9525108, -1.9904976, -1.8394413, -1.5863228, -1.6402569, -1.5654182, -1.4741344, -2.0050507, -2.1075935, -2.2592182, -1.7204514, -1.6667385, -2.083683, -2.320427, -2.441496, -1.6861687, -0.87742424, -1.6289558, -1.2047195, -2.009037, -1.394825, -1.0305634, -1.8512383, -2.0232716, -1.9782982, -1.7630978, -1.166193, -1.8723545, -1.4831142, -2.2475853, -2.1557293, -1.9700489, -2.2183762, -2.3362007, -1.8346443]\n",
      "-1.6611787\n",
      "0.2516402\n",
      "tensor([ 2.5827,  2.5673,  2.5520,  2.5951,  2.6898,  2.6362,  2.6432,  2.6558,\n",
      "         2.5567,  2.3979,  2.4710,  2.6645,  2.5505,  2.5875,  2.6857,  2.7244,\n",
      "         2.7452,  2.6042,  2.8106,  2.8407,  2.8857,  2.4839,  2.6115,  2.3851,\n",
      "         2.3999,  2.4302,  2.3272,  2.5744,  2.4337,  2.2445,  2.3058,  2.4119,\n",
      "         2.6847,  2.8259,  2.6960,  2.7206,  2.5569,  2.6176,  2.4842,  2.3598,\n",
      "         1.5899,  1.8028,  1.0520,  1.9977,  1.0319,  0.9901,  0.8937,  1.9504,\n",
      "         1.1554,  1.3069,  0.5749,  2.2119,  2.7412,  3.1488,  2.3651,  2.7258,\n",
      "         2.5025,  0.9166,  2.5926,  0.4515, -0.2931,  0.1447,  1.1237, -0.3645,\n",
      "         0.5517,  0.2681,  0.4672,  0.3974,  1.8433,  0.6282,  2.0295,  0.9691,\n",
      "         2.2326,  0.5643,  3.2279,  3.1141, -0.3508,  1.8208,  2.0076,  2.1844,\n",
      "         0.2901,  0.8486,  0.0817,  1.3026,  1.1041,  1.5491,  1.2554,  1.5898,\n",
      "         0.4025,  2.2643,  1.3357,  2.5440,  1.3202,  1.7733,  1.4783, -0.2222,\n",
      "         1.8895, -0.1723,  0.0475, -0.0310, -0.1161, -0.4718, -1.4138, -0.3512,\n",
      "         0.4671,  1.1879,  0.5436,  0.1259,  0.1496,  0.3697,  0.3606,  0.4664,\n",
      "         0.3683,  0.3923, -0.0399,  1.4799,  3.4568,  2.9915,  2.8299,  2.7791,\n",
      "         1.8123,  3.1065,  3.7257,  3.2747,  2.6586,  1.9408,  4.5945])\n",
      "[[1.         0.08719221]\n",
      " [0.08719221 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_mut_dG = []\n",
    "for i in range(1,NUMBER_OF_VARIANTS):\n",
    "    if i == wt_index:\n",
    "        continue\n",
    "    seq_one_hot = mutations_data['one_hot'][i]\n",
    "    proT5_emb = mutations_data['prott5'][i]\n",
    "    mask = mutations_data['masks'][0]\n",
    "    coords_tensor = mutations_data['coords']\n",
    "    protein_graph = get_graph( coords_tensor ,seq_one_hot, proT5_emb,mask)\n",
    "    protein_unfolded_graph = get_unfolded_graph( coords_tensor ,seq_one_hot, proT5_emb,mask)\n",
    "    pred_deltaG = calculate_dG(protein_graph, protein_unfolded_graph)\n",
    "    pred_mut_dG.append(pred_deltaG)\n",
    "\n",
    "print(pred_mut_dG)\n",
    "#average dG\n",
    "print(np.mean(pred_mut_dG))\n",
    "#avarage ddG\n",
    "print(np.mean(pred_mut_dG)-pred_wt_deltaG)\n",
    "#calculate the correlation\n",
    "true_dG = mutations_data['delta_g'][1:NUMBER_OF_VARIANTS]\n",
    "print(true_dG)\n",
    "print(np.corrcoef(pred_mut_dG,true_dG))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the experiment with many proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tensor_root_dir, mutations_root_dir, remove_TM = False, one_mut = True):\n",
    "        self.tensor_root_dir = tensor_root_dir\n",
    "        self.mutations_root_dir = mutations_root_dir\n",
    "        self.protein_dirs = [protein for i, protein in enumerate(os.listdir(self.tensor_root_dir))]\n",
    "        self.one_mut = one_mut # remove the mutations with more than one mutation\n",
    "        # remove TM proteins \n",
    "        if remove_TM:\n",
    "            tm_proteins = pd.read_csv(TM_PATH)\n",
    "            tm_proteins = tm_proteins['name'].apply(lambda x: x.split(\".\")[0]).unique().tolist()\n",
    "            self.protein_dirs = [protein for protein in self.protein_dirs if protein not in tm_proteins]\n",
    "        if DEBUG:\n",
    "            self.protein_dirs = self.protein_dirs[:5]\n",
    "        # # Train test split\n",
    "        # self.training_protein, self.val_proteins = train_test_split(self.protein_dirs, test_size=VAL_RATIO, random_state=RANDOM_SEED)\n",
    "        # if train:\n",
    "        #     self.protein_dirs = self.training_protein\n",
    "        # else:\n",
    "        #     self.protein_dirs = self.val_proteins\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.protein_dirs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        protein_dir = os.path.join(self.tensor_root_dir, self.protein_dirs[idx])\n",
    "        mutations_path = os.path.join(self.mutations_root_dir, f'{self.protein_dirs[idx]}.csv')\n",
    "        mutations = pd.read_csv(mutations_path)\n",
    "        mutations = mutations[~mutations['mut_type'].str.contains('ins|del')].reset_index(drop=True)\n",
    "        # Load and preprocess the data for each protein\n",
    "        coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
    "        delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
    "        mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
    "        one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
    "        embedding_tensor = load_embedding_tensor(os.path.join(protein_dir, PROTT5_EMBEDDINGS))\n",
    "        \n",
    "        # remove the mutations with more than one mutation\n",
    "        if self.one_mut:\n",
    "            one_mut_index = mutations[~mutations['mut_type'].str.contains(':')]\n",
    "            mutations = mutations.loc[one_mut_index.index]\n",
    "            delta_g_tensor = delta_g_tensor[one_mut_index.index]\n",
    "            one_hot_tensor = one_hot_tensor[one_mut_index.index]\n",
    "            embedding_tensor = embedding_tensor[one_mut_index.index]\n",
    "            \n",
    "        mutations_data = {\n",
    "            'name': self.protein_dirs[idx],\n",
    "            'mutations': mutations['mut_type'].to_list(),\n",
    "            'prott5': embedding_tensor,\n",
    "            'coords': coords_tensor,\n",
    "            'one_hot': one_hot_tensor,\n",
    "            'delta_g': delta_g_tensor,\n",
    "            'masks': mask_tensor\n",
    "        }\n",
    "\n",
    "        return mutations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '1A0N', 'mutations': ['wt', 'wt', 'wt', 'wt', 'wt', 'V1Q', 'V1E', 'V1N', 'V1H', 'V1D', 'V1R', 'V1K', 'V1T', 'V1S', 'V1A', 'V1G', 'V1M', 'V1L', 'V1I', 'V1W', 'V1Y', 'V1F', 'V1P', 'T2Q', 'T2E', 'T2N', 'T2H', 'T2D', 'T2R', 'T2K', 'T2S', 'T2A', 'T2G', 'T2M', 'T2L', 'T2V', 'T2I', 'T2W', 'T2Y', 'T2F', 'T2P', 'L3Q', 'L3E', 'L3N', 'L3H', 'L3D', 'L3R', 'L3K', 'L3T', 'L3S', 'L3A', 'L3G', 'L3M', 'L3V', 'L3I', 'L3W', 'L3Y', 'L3F', 'L3P', 'L3C', 'F4Q', 'F4E', 'F4N', 'F4H', 'F4D', 'F4R', 'F4K', 'F4T', 'F4S', 'F4A', 'F4G', 'F4M', 'F4L', 'F4V', 'F4I', 'F4W', 'F4Y', 'F4P', 'F4C', 'V5Q', 'V5E', 'V5N', 'V5H', 'V5D', 'V5R', 'V5K', 'V5T', 'V5S', 'V5A', 'V5G', 'V5M', 'V5L', 'V5I', 'V5W', 'V5Y', 'V5F', 'V5P', 'V5C', 'A6Q', 'A6E', 'A6N', 'A6H', 'A6D', 'A6R', 'A6K', 'A6T', 'A6S', 'A6G', 'A6M', 'A6L', 'A6V', 'A6I', 'A6W', 'A6Y', 'A6F', 'A6P', 'A6C', 'S7Q', 'S7E', 'S7N', 'S7H', 'S7D', 'S7R', 'S7K', 'S7T', 'S7A', 'S7G', 'S7M', 'S7L', 'S7V', 'S7I', 'S7W', 'S7Y', 'S7F', 'S7P', 'S7C', 'Y8Q', 'Y8E', 'Y8N', 'Y8H', 'Y8D', 'Y8R', 'Y8K', 'Y8T', 'Y8S', 'Y8A', 'Y8G', 'Y8M', 'Y8L', 'Y8V', 'Y8I', 'Y8W', 'Y8F', 'Y8P', 'Y8C', 'D9Q', 'D9E', 'D9N', 'D9H', 'D9R', 'D9K', 'D9T', 'D9S', 'D9A', 'D9G', 'D9M', 'D9L', 'D9V', 'D9I', 'D9W', 'D9Y', 'D9F', 'D9P', 'D9C', 'Y10Q', 'Y10E', 'Y10N', 'Y10H', 'Y10D', 'Y10R', 'Y10K', 'Y10T', 'Y10S', 'Y10A', 'Y10G', 'Y10M', 'Y10L', 'Y10V', 'Y10I', 'Y10W', 'Y10F', 'Y10P', 'Y10C', 'E11Q', 'E11H', 'E11D', 'E11R', 'E11K', 'E11T', 'E11S', 'E11A', 'E11G', 'E11M', 'E11L', 'E11V', 'E11I', 'E11W', 'E11Y', 'E11F', 'E11P', 'E11C', 'A12Q', 'A12E', 'A12N', 'A12H', 'A12D', 'A12R', 'A12K', 'A12T', 'A12S', 'A12G', 'A12M', 'A12L', 'A12V', 'A12I', 'A12W', 'A12Y', 'A12F', 'A12P', 'A12C', 'R13Q', 'R13E', 'R13N', 'R13H', 'R13D', 'R13K', 'R13T', 'R13S', 'R13A', 'R13G', 'R13M', 'R13L', 'R13I', 'R13W', 'R13Y', 'R13F', 'R13P', 'R13C', 'T14Q', 'T14E', 'T14N', 'T14H', 'T14D', 'T14R', 'T14K', 'T14S', 'T14A', 'T14G', 'T14M', 'T14L', 'T14V', 'T14I', 'T14W', 'T14Y', 'T14F', 'T14P', 'E15Q', 'E15N', 'E15H', 'E15D', 'E15R', 'E15K', 'E15T', 'E15S', 'E15A', 'E15G', 'E15M', 'E15L', 'E15V', 'E15I', 'E15W', 'E15Y', 'E15F', 'E15P', 'E15C', 'D16Q', 'D16E', 'D16N', 'D16H', 'D16R', 'D16K', 'D16T', 'D16S', 'D16A', 'D16G', 'D16M', 'D16L', 'D16V', 'D16I', 'D16W', 'D16Y', 'D16F', 'D16P', 'D17Q', 'D17E', 'D17N', 'D17H', 'D17R', 'D17K', 'D17T', 'D17S', 'D17A', 'D17G', 'D17M', 'D17L', 'D17V', 'D17I', 'D17W', 'D17Y', 'D17F', 'D17P', 'D17C', 'L18Q', 'L18E', 'L18N', 'L18H', 'L18D', 'L18R', 'L18K', 'L18T', 'L18S', 'L18A', 'L18G', 'L18M', 'L18V', 'L18I', 'L18W', 'L18Y', 'L18F', 'L18P', 'L18C', 'S19Q', 'S19E', 'S19N', 'S19H', 'S19D', 'S19R', 'S19K', 'S19T', 'S19A', 'S19G', 'S19M', 'S19L', 'S19V', 'S19I', 'S19W', 'S19Y', 'S19F', 'S19P', 'S19C', 'F20Q', 'F20E', 'F20N', 'F20H', 'F20D', 'F20R', 'F20K', 'F20T', 'F20S', 'F20A', 'F20G', 'F20M', 'F20L', 'F20V', 'F20I', 'F20W', 'F20Y', 'F20P', 'F20C', 'H21Q', 'H21E', 'H21N', 'H21D', 'H21R', 'H21K', 'H21T', 'H21S', 'H21A', 'H21G', 'H21M', 'H21L', 'H21V', 'H21I', 'H21W', 'H21Y', 'H21F', 'H21P', 'H21C', 'K22Q', 'K22E', 'K22N', 'K22H', 'K22D', 'K22R', 'K22T', 'K22S', 'K22A', 'K22G', 'K22M', 'K22L', 'K22V', 'K22I', 'K22W', 'K22Y', 'K22F', 'K22P', 'K22C', 'G23Q', 'G23E', 'G23N', 'G23H', 'G23D', 'G23R', 'G23K', 'G23T', 'G23S', 'G23A', 'G23M', 'G23L', 'G23V', 'G23I', 'G23W', 'G23Y', 'G23F', 'G23P', 'G23C', 'E24Q', 'E24N', 'E24H', 'E24D', 'E24R', 'E24K', 'E24T', 'E24S', 'E24A', 'E24G', 'E24M', 'E24L', 'E24V', 'E24I', 'E24W', 'E24Y', 'E24F', 'E24P', 'E24C', 'K25Q', 'K25E', 'K25N', 'K25H', 'K25D', 'K25R', 'K25T', 'K25S', 'K25A', 'K25G', 'K25M', 'K25L', 'K25V', 'K25I', 'K25W', 'K25Y', 'K25F', 'K25P', 'K25C', 'F26Q', 'F26E', 'F26N', 'F26H', 'F26D', 'F26R', 'F26K', 'F26T', 'F26S', 'F26A', 'F26G', 'F26M', 'F26L', 'F26V', 'F26I', 'F26W', 'F26Y', 'F26P', 'F26C', 'Q27E', 'Q27N', 'Q27H', 'Q27D', 'Q27R', 'Q27K', 'Q27T', 'Q27S', 'Q27A', 'Q27G', 'Q27M', 'Q27L', 'Q27V', 'Q27I', 'Q27W', 'Q27Y', 'Q27F', 'Q27P', 'Q27C', 'I28Q', 'I28E', 'I28N', 'I28H', 'I28D', 'I28R', 'I28K', 'I28T', 'I28S', 'I28A', 'I28G', 'I28M', 'I28L', 'I28V', 'I28W', 'I28Y', 'I28F', 'I28P', 'I28C', 'L29Q', 'L29E', 'L29N', 'L29H', 'L29D', 'L29R', 'L29K', 'L29T', 'L29S', 'L29A', 'L29G', 'L29M', 'L29V', 'L29I', 'L29W', 'L29Y', 'L29F', 'L29P', 'L29C', 'N30Q', 'N30E', 'N30H', 'N30D', 'N30R', 'N30K', 'N30T', 'N30S', 'N30A', 'N30G', 'N30M', 'N30L', 'N30V', 'N30I', 'N30W', 'N30Y', 'N30F', 'N30P', 'N30C', 'S31Q', 'S31E', 'S31N', 'S31H', 'S31D', 'S31R', 'S31K', 'S31T', 'S31A', 'S31G', 'S31M', 'S31L', 'S31V', 'S31I', 'S31W', 'S31Y', 'S31F', 'S31P', 'S32Q', 'S32E', 'S32N', 'S32H', 'S32D', 'S32R', 'S32K', 'S32T', 'S32A', 'S32G', 'S32M', 'S32L', 'S32V', 'S32I', 'S32W', 'S32Y', 'S32F', 'S32P', 'S32C', 'E33Q', 'E33N', 'E33H', 'E33D', 'E33R', 'E33K', 'E33T', 'E33S', 'E33A', 'E33G', 'E33M', 'E33L', 'E33V', 'E33I', 'E33W', 'E33Y', 'E33F', 'E33P', 'E33C', 'G34Q', 'G34E', 'G34N', 'G34H', 'G34D', 'G34R', 'G34K', 'G34T', 'G34S', 'G34A', 'G34M', 'G34L', 'G34V', 'G34I', 'G34W', 'G34Y', 'G34F', 'G34P', 'G34C', 'D35Q', 'D35E', 'D35N', 'D35H', 'D35R', 'D35K', 'D35T', 'D35S', 'D35A', 'D35G', 'D35M', 'D35L', 'D35V', 'D35I', 'D35W', 'D35Y', 'D35F', 'D35P', 'D35C', 'W36Q', 'W36E', 'W36N', 'W36H', 'W36D', 'W36R', 'W36K', 'W36T', 'W36S', 'W36A', 'W36G', 'W36M', 'W36L', 'W36V', 'W36I', 'W36Y', 'W36F', 'W36P', 'W36C', 'W37Q', 'W37E', 'W37N', 'W37H', 'W37D', 'W37R', 'W37K', 'W37T', 'W37S', 'W37A', 'W37G', 'W37M', 'W37L', 'W37V', 'W37I', 'W37Y', 'W37F', 'W37P', 'W37C', 'E38Q', 'E38N', 'E38H', 'E38D', 'E38R', 'E38K', 'E38T', 'E38S', 'E38A', 'E38G', 'E38M', 'E38L', 'E38V', 'E38I', 'E38W', 'E38Y', 'E38F', 'E38P', 'E38C', 'A39Q', 'A39E', 'A39N', 'A39H', 'A39D', 'A39R', 'A39K', 'A39T', 'A39S', 'A39G', 'A39M', 'A39L', 'A39V', 'A39I', 'A39W', 'A39Y', 'A39F', 'A39P', 'A39C', 'R40Q', 'R40E', 'R40N', 'R40H', 'R40D', 'R40K', 'R40T', 'R40S', 'R40A', 'R40G', 'R40M', 'R40L', 'R40V', 'R40I', 'R40W', 'R40Y', 'R40F', 'R40P', 'R40C', 'S41Q', 'S41E', 'S41N', 'S41H', 'S41D', 'S41R', 'S41K', 'S41T', 'S41A', 'S41G', 'S41M', 'S41L', 'S41V', 'S41I', 'S41W', 'S41Y', 'S41F', 'S41P', 'S41C', 'L42Q', 'L42E', 'L42N', 'L42H', 'L42D', 'L42R', 'L42K', 'L42T', 'L42S', 'L42A', 'L42G', 'L42M', 'L42V', 'L42I', 'L42W', 'L42Y', 'L42F', 'L42P', 'L42C', 'T43Q', 'T43E', 'T43N', 'T43H', 'T43D', 'T43R', 'T43K', 'T43S', 'T43A', 'T43G', 'T43M', 'T43L', 'T43V', 'T43I', 'T43W', 'T43Y', 'T43F', 'T43P', 'T43C', 'T44Q', 'T44E', 'T44N', 'T44H', 'T44D', 'T44R', 'T44K', 'T44S', 'T44A', 'T44G', 'T44M', 'T44L', 'T44V', 'T44I', 'T44W', 'T44Y', 'T44F', 'T44P', 'T44C', 'G45Q', 'G45E', 'G45N', 'G45H', 'G45D', 'G45R', 'G45K', 'G45T', 'G45S', 'G45A', 'G45M', 'G45L', 'G45V', 'G45I', 'G45W', 'G45Y', 'G45F', 'G45P', 'G45C', 'E46Q', 'E46N', 'E46H', 'E46D', 'E46R', 'E46K', 'E46T', 'E46S', 'E46A', 'E46G', 'E46M', 'E46L', 'E46V', 'E46I', 'E46W', 'E46Y', 'E46F', 'E46P', 'E46C', 'T47Q', 'T47E', 'T47N', 'T47H', 'T47D', 'T47R', 'T47K', 'T47S', 'T47A', 'T47G', 'T47M', 'T47L', 'T47V', 'T47I', 'T47W', 'T47Y', 'T47F', 'T47P', 'T47C', 'G48Q', 'G48E', 'G48N', 'G48H', 'G48D', 'G48R', 'G48K', 'G48T', 'G48S', 'G48A', 'G48M', 'G48L', 'G48V', 'G48I', 'G48W', 'G48Y', 'G48F', 'G48P', 'G48C', 'Y49Q', 'Y49E', 'Y49N', 'Y49H', 'Y49D', 'Y49R', 'Y49K', 'Y49T', 'Y49S', 'Y49A', 'Y49G', 'Y49M', 'Y49L', 'Y49V', 'Y49I', 'Y49W', 'Y49F', 'Y49P', 'Y49C', 'I50Q', 'I50E', 'I50N', 'I50H', 'I50D', 'I50R', 'I50K', 'I50T', 'I50S', 'I50A', 'I50G', 'I50M', 'I50L', 'I50V', 'I50W', 'I50Y', 'I50F', 'I50P', 'I50C', 'P51Q', 'P51E', 'P51N', 'P51H', 'P51D', 'P51R', 'P51K', 'P51T', 'P51S', 'P51A', 'P51G', 'P51M', 'P51L', 'P51V', 'P51I', 'P51W', 'P51Y', 'P51F', 'P51C', 'S52Q', 'S52E', 'S52N', 'S52H', 'S52D', 'S52R', 'S52K', 'S52T', 'S52A', 'S52G', 'S52M', 'S52L', 'S52V', 'S52I', 'S52W', 'S52Y', 'S52F', 'S52P', 'S52C', 'N53Q', 'N53E', 'N53H', 'N53D', 'N53R', 'N53K', 'N53T', 'N53S', 'N53A', 'N53G', 'N53M', 'N53L', 'N53V', 'N53I', 'N53W', 'N53Y', 'N53F', 'N53P', 'N53C', 'Y54Q', 'Y54E', 'Y54N', 'Y54H', 'Y54D', 'Y54R', 'Y54K', 'Y54T', 'Y54S', 'Y54A', 'Y54G', 'Y54M', 'Y54L', 'Y54V', 'Y54I', 'Y54W', 'Y54F', 'Y54P', 'Y54C', 'V55Q', 'V55E', 'V55N', 'V55H', 'V55D', 'V55R', 'V55K', 'V55T', 'V55S', 'V55A', 'V55G', 'V55M', 'V55L', 'V55I', 'V55W', 'V55Y', 'V55F', 'V55P', 'V55C', 'A56Q', 'A56E', 'A56N', 'A56H', 'A56D', 'A56R', 'A56K', 'A56T', 'A56S', 'A56G', 'A56M', 'A56L', 'A56V', 'A56I', 'A56W', 'A56Y', 'A56F', 'A56P', 'A56C', 'P57Q', 'P57E', 'P57N', 'P57H', 'P57D', 'P57R', 'P57K', 'P57T', 'P57S', 'P57A', 'P57G', 'P57M', 'P57L', 'P57V', 'P57I', 'P57W', 'P57Y', 'P57F', 'P57C', 'V58Q', 'V58E', 'V58N', 'V58H', 'V58D', 'V58R', 'V58K', 'V58T', 'V58S', 'V58A', 'V58G', 'V58M', 'V58L', 'V58I', 'V58W', 'V58Y', 'V58F', 'V58P', 'V58C', 'V1C', 'T2C', 'T14C', 'D16C', 'S31C', 'wt', 'wt', 'wt', 'wt', 'wt', 'V1Q', 'V1E', 'V1N', 'V1H', 'V1D', 'V1R', 'V1K', 'V1T', 'V1S', 'V1A', 'V1G', 'V1M', 'V1L', 'V1I', 'V1W', 'V1Y', 'V1F', 'V1P', 'V1C', 'T2Q', 'T2E', 'T2N', 'T2H', 'T2D', 'T2R', 'T2K', 'T2S', 'T2A', 'T2G', 'T2M', 'T2L', 'T2V', 'T2I', 'T2W', 'T2Y', 'T2F', 'T2P', 'T2C', 'L3Q', 'L3E', 'L3N', 'L3H', 'L3D', 'L3R', 'L3K', 'L3T', 'L3S', 'L3A', 'L3G', 'L3M', 'L3V', 'L3I', 'L3W', 'L3Y', 'L3F', 'L3P', 'L3C', 'F4Q', 'F4E', 'F4N', 'F4H', 'F4D', 'F4R', 'F4K', 'F4T', 'F4S', 'F4A', 'F4G', 'F4M', 'F4L', 'F4V', 'F4I', 'F4W', 'F4Y', 'F4P', 'F4C', 'V5Q', 'V5E', 'V5N', 'V5H', 'V5D', 'V5R', 'V5K', 'V5T', 'V5S', 'V5A', 'V5G', 'V5M', 'V5L', 'V5I', 'V5W', 'V5Y', 'V5F', 'V5P', 'V5C', 'A6Q', 'A6E', 'A6N', 'A6H', 'A6D', 'A6R', 'A6K', 'A6T', 'A6S', 'A6G', 'A6M', 'A6L', 'A6V', 'A6I', 'A6W', 'A6Y', 'A6F', 'A6P', 'A6C', 'L7Q', 'L7E', 'L7N', 'L7H', 'L7D', 'L7R', 'L7K', 'L7T', 'L7S', 'L7A', 'L7G', 'L7M', 'L7V', 'L7I', 'L7W', 'L7Y', 'L7F', 'L7P', 'L7C', 'Y8Q', 'Y8E', 'Y8N', 'Y8H', 'Y8D', 'Y8R', 'Y8K', 'Y8T', 'Y8S', 'Y8A', 'Y8G', 'Y8M', 'Y8L', 'Y8V', 'Y8I', 'Y8W', 'Y8F', 'Y8P', 'Y8C', 'D9Q', 'D9E', 'D9N', 'D9H', 'D9R', 'D9K', 'D9T', 'D9S', 'D9A', 'D9G', 'D9M', 'D9L', 'D9V', 'D9I', 'D9W', 'D9Y', 'D9F', 'D9P', 'D9C', 'Y10Q', 'Y10E', 'Y10N', 'Y10H', 'Y10D', 'Y10R', 'Y10K', 'Y10T', 'Y10S', 'Y10A', 'Y10G', 'Y10M', 'Y10L', 'Y10V', 'Y10I', 'Y10W', 'Y10F', 'Y10P', 'Y10C', 'E11Q', 'E11N', 'E11H', 'E11D', 'E11R', 'E11K', 'E11T', 'E11S', 'E11A', 'E11G', 'E11M', 'E11L', 'E11V', 'E11I', 'E11W', 'E11Y', 'E11F', 'E11P', 'E11C', 'A12Q', 'A12E', 'A12N', 'A12H', 'A12D', 'A12R', 'A12K', 'A12T', 'A12S', 'A12G', 'A12M', 'A12L', 'A12V', 'A12I', 'A12W', 'A12Y', 'A12F', 'A12P', 'A12C', 'R13Q', 'R13E', 'R13N', 'R13H', 'R13D', 'R13K', 'R13T', 'R13S', 'R13A', 'R13G', 'R13M', 'R13L', 'R13V', 'R13I', 'R13W', 'R13Y', 'R13F', 'R13P', 'R13C', 'T14Q', 'T14E', 'T14N', 'T14H', 'T14D', 'T14R', 'T14K', 'T14S', 'T14A', 'T14G', 'T14M', 'T14L', 'T14V', 'T14I', 'T14W', 'T14Y', 'T14F', 'T14P', 'E15Q', 'E15N', 'E15H', 'E15D', 'E15R', 'E15K', 'E15T', 'E15S', 'E15A', 'E15G', 'E15M', 'E15L', 'E15V', 'E15I', 'E15W', 'E15Y', 'E15F', 'E15P', 'E15C', 'D16Q', 'D16E', 'D16N', 'D16H', 'D16R', 'D16K', 'D16T', 'D16S', 'D16A', 'D16G', 'D16M', 'D16L', 'D16V', 'D16I', 'D16W', 'D16Y', 'D16F', 'D16P', 'D16C', 'D17Q', 'D17E', 'D17N', 'D17H', 'D17R', 'D17K', 'D17T', 'D17S', 'D17A', 'D17G', 'D17M', 'D17L', 'D17V', 'D17I', 'D17W', 'D17Y', 'D17F', 'D17P', 'D17C', 'L18Q', 'L18E', 'L18N', 'L18H', 'L18D', 'L18R', 'L18K', 'L18T', 'L18S', 'L18A', 'L18G', 'L18M', 'L18V', 'L18I', 'L18W', 'L18Y', 'L18F', 'L18P', 'L18C', 'S19Q', 'S19N', 'S19H', 'S19D', 'S19R', 'S19K', 'S19T', 'S19A', 'S19G', 'S19M', 'S19L', 'S19V', 'S19I', 'S19W', 'S19Y', 'S19F', 'S19P', 'S19C', 'F20Q', 'F20E', 'F20N', 'F20H', 'F20D', 'F20R', 'F20K', 'F20T', 'F20S', 'F20A', 'F20G', 'F20M', 'F20L', 'F20V', 'F20I', 'F20W', 'F20Y', 'F20P', 'F20C', 'H21Q', 'H21E', 'H21N', 'H21D', 'H21R', 'H21K', 'H21T', 'H21S', 'H21A', 'H21G', 'H21M', 'H21L', 'H21V', 'H21I', 'H21W', 'H21Y', 'H21F', 'H21P', 'H21C', 'K22Q', 'K22E', 'K22N', 'K22H', 'K22D', 'K22R', 'K22T', 'K22S', 'K22A', 'K22G', 'K22M', 'K22L', 'K22V', 'K22I', 'K22W', 'K22Y', 'K22F', 'K22P', 'K22C', 'G23Q', 'G23E', 'G23N', 'G23H', 'G23D', 'G23R', 'G23K', 'G23T', 'G23S', 'G23A', 'G23M', 'G23L', 'G23V', 'G23I', 'G23W', 'G23Y', 'G23F', 'G23P', 'G23C', 'E24Q', 'E24N', 'E24H', 'E24D', 'E24R', 'E24K', 'E24T', 'E24S', 'E24A', 'E24G', 'E24M', 'E24L', 'E24V', 'E24I', 'E24W', 'E24Y', 'E24F', 'E24P', 'E24C', 'K25Q', 'K25E', 'K25N', 'K25H', 'K25D', 'K25R', 'K25T', 'K25S', 'K25A', 'K25G', 'K25M', 'K25L', 'K25V', 'K25I', 'K25W', 'K25Y', 'K25F', 'K25P', 'K25C', 'F26Q', 'F26E', 'F26N', 'F26H', 'F26D', 'F26R', 'F26K', 'F26T', 'F26S', 'F26A', 'F26G', 'F26M', 'F26L', 'F26V', 'F26I', 'F26W', 'F26Y', 'F26P', 'F26C', 'Q27E', 'Q27N', 'Q27H', 'Q27D', 'Q27R', 'Q27K', 'Q27T', 'Q27S', 'Q27A', 'Q27G', 'Q27M', 'Q27L', 'Q27V', 'Q27I', 'Q27W', 'Q27Y', 'Q27F', 'Q27P', 'Q27C', 'I28Q', 'I28E', 'I28N', 'I28H', 'I28D', 'I28R', 'I28K', 'I28T', 'I28S', 'I28A', 'I28G', 'I28M', 'I28L', 'I28V', 'I28W', 'I28Y', 'I28F', 'I28P', 'I28C', 'L29Q', 'L29E', 'L29N', 'L29H', 'L29D', 'L29R', 'L29K', 'L29T', 'L29S', 'L29A', 'L29G', 'L29M', 'L29V', 'L29I', 'L29W', 'L29Y', 'L29F', 'L29P', 'L29C', 'N30Q', 'N30E', 'N30H', 'N30D', 'N30R', 'N30K', 'N30T', 'N30S', 'N30A', 'N30G', 'N30M', 'N30L', 'N30V', 'N30I', 'N30W', 'N30Y', 'N30F', 'N30P', 'N30C', 'S31Q', 'S31E', 'S31N', 'S31H', 'S31D', 'S31R', 'S31K', 'S31T', 'S31A', 'S31G', 'S31M', 'S31L', 'S31V', 'S31I', 'S31W', 'S31Y', 'S31F', 'S31P', 'S31C', 'S32Q', 'S32E', 'S32N', 'S32H', 'S32D', 'S32R', 'S32K', 'S32T', 'S32A', 'S32G', 'S32M', 'S32L', 'S32V', 'S32I', 'S32W', 'S32Y', 'S32F', 'S32P', 'S32C', 'E33Q', 'E33N', 'E33H', 'E33D', 'E33R', 'E33K', 'E33T', 'E33S', 'E33A', 'E33G', 'E33M', 'E33L', 'E33V', 'E33I', 'E33W', 'E33Y', 'E33F', 'E33P', 'E33C', 'G34Q', 'G34E', 'G34N', 'G34H', 'G34D', 'G34R', 'G34K', 'G34T', 'G34S', 'G34A', 'G34L', 'G34V', 'G34I', 'G34W', 'G34Y', 'G34F', 'G34P', 'G34C', 'D35Q', 'D35E', 'D35N', 'D35H', 'D35R', 'D35K', 'D35T', 'D35S', 'D35A', 'D35G', 'D35M', 'D35L', 'D35V', 'D35I', 'D35W', 'D35Y', 'D35F', 'D35P', 'D35C', 'W36Q', 'W36E', 'W36N', 'W36H', 'W36D', 'W36R', 'W36K', 'W36T', 'W36S', 'W36A', 'W36G', 'W36M', 'W36L', 'W36V', 'W36I', 'W36Y', 'W36F', 'W36P', 'W36C', 'W37Q', 'W37E', 'W37N', 'W37H', 'W37D', 'W37R', 'W37K', 'W37T', 'W37S', 'W37A', 'W37G', 'W37M', 'W37L', 'W37V', 'W37I', 'W37Y', 'W37F', 'W37P', 'W37C', 'E38Q', 'E38N', 'E38H', 'E38D', 'E38R', 'E38K', 'E38T', 'E38S', 'E38A', 'E38G', 'E38M', 'E38L', 'E38V', 'E38I', 'E38W', 'E38Y', 'E38F', 'E38P', 'E38C', 'A39Q', 'A39E', 'A39N', 'A39H', 'A39D', 'A39R', 'A39K', 'A39T', 'A39S', 'A39G', 'A39M', 'A39L', 'A39V', 'A39I', 'A39W', 'A39Y', 'A39F', 'A39P', 'A39C', 'R40Q', 'R40E', 'R40N', 'R40H', 'R40D', 'R40K', 'R40T', 'R40S', 'R40A', 'R40G', 'R40M', 'R40L', 'R40V', 'R40I', 'R40W', 'R40Y', 'R40F', 'R40P', 'R40C', 'S41Q', 'S41E', 'S41N', 'S41H', 'S41D', 'S41R', 'S41K', 'S41T', 'S41A', 'S41G', 'S41M', 'S41L', 'S41V', 'S41I', 'S41W', 'S41Y', 'S41F', 'S41P', 'S41C', 'L42Q', 'L42E', 'L42N', 'L42H', 'L42D', 'L42R', 'L42K', 'L42T', 'L42S', 'L42A', 'L42G', 'L42M', 'L42V', 'L42I', 'L42W', 'L42Y', 'L42F', 'L42P', 'L42C', 'T43Q', 'T43E', 'T43N', 'T43H', 'T43D', 'T43R', 'T43K', 'T43S', 'T43A', 'T43G', 'T43M', 'T43L', 'T43V', 'T43I', 'T43W', 'T43Y', 'T43F', 'T43P', 'T43C', 'T44Q', 'T44E', 'T44N', 'T44H', 'T44D', 'T44R', 'T44K', 'T44S', 'T44A', 'T44G', 'T44M', 'T44L', 'T44V', 'T44I', 'T44W', 'T44Y', 'T44F', 'T44P', 'T44C', 'G45Q', 'G45E', 'G45N', 'G45H', 'G45D', 'G45R', 'G45K', 'G45T', 'G45S', 'G45A', 'G45M', 'G45L', 'G45V', 'G45I', 'G45W', 'G45Y', 'G45F', 'G45P', 'G45C', 'E46Q', 'E46N', 'E46H', 'E46D', 'E46R', 'E46K', 'E46T', 'E46S', 'E46A', 'E46G', 'E46M', 'E46L', 'E46V', 'E46I', 'E46W', 'E46Y', 'E46F', 'E46P', 'E46C', 'T47Q', 'T47E', 'T47N', 'T47H', 'T47D', 'T47R', 'T47K', 'T47S', 'T47A', 'T47G', 'T47M', 'T47L', 'T47V', 'T47I', 'T47W', 'T47Y', 'T47F', 'T47P', 'T47C', 'G48Q', 'G48E', 'G48N', 'G48H', 'G48D', 'G48R', 'G48K', 'G48T', 'G48S', 'G48A', 'G48M', 'G48L', 'G48V', 'G48I', 'G48W', 'G48Y', 'G48F', 'G48P', 'G48C', 'Y49Q', 'Y49E', 'Y49N', 'Y49H', 'Y49D', 'Y49R', 'Y49K', 'Y49T', 'Y49S', 'Y49A', 'Y49G', 'Y49M', 'Y49L', 'Y49V', 'Y49I', 'Y49W', 'Y49F', 'Y49P', 'Y49C', 'I50Q', 'I50E', 'I50N', 'I50H', 'I50D', 'I50R', 'I50K', 'I50T', 'I50S', 'I50A', 'I50G', 'I50M', 'I50L', 'I50V', 'I50W', 'I50Y', 'I50F', 'I50P', 'I50C', 'P51Q', 'P51E', 'P51N', 'P51H', 'P51D', 'P51R', 'P51K', 'P51T', 'P51S', 'P51A', 'P51G', 'P51M', 'P51L', 'P51V', 'P51I', 'P51W', 'P51Y', 'P51F', 'P51C', 'S52Q', 'S52E', 'S52N', 'S52H', 'S52D', 'S52R', 'S52K', 'S52T', 'S52A', 'S52G', 'S52M', 'S52L', 'S52V', 'S52I', 'S52W', 'S52Y', 'S52F', 'S52P', 'S52C', 'N53Q', 'N53E', 'N53H', 'N53D', 'N53R', 'N53K', 'N53T', 'N53S', 'N53A', 'N53G', 'N53M', 'N53L', 'N53V', 'N53I', 'N53W', 'N53Y', 'N53F', 'N53P', 'N53C', 'Y54Q', 'Y54E', 'Y54N', 'Y54H', 'Y54D', 'Y54R', 'Y54K', 'Y54T', 'Y54S', 'Y54A', 'Y54G', 'Y54M', 'Y54L', 'Y54V', 'Y54I', 'Y54W', 'Y54F', 'Y54P', 'Y54C', 'A55Q', 'A55E', 'A55N', 'A55H', 'A55D', 'A55R', 'A55K', 'A55T', 'A55S', 'A55G', 'A55M', 'A55L', 'A55V', 'A55I', 'A55W', 'A55Y', 'A55F', 'A55P', 'A55C', 'A56Q', 'A56E', 'A56N', 'A56H', 'A56D', 'A56R', 'A56K', 'A56T', 'A56S', 'A56G', 'A56M', 'A56L', 'A56V', 'A56I', 'A56W', 'A56Y', 'A56F', 'A56P', 'A56C', 'P57Q', 'P57E', 'P57N', 'P57H', 'P57D', 'P57R', 'P57K', 'P57T', 'P57S', 'P57A', 'P57G', 'P57M', 'P57L', 'P57V', 'P57I', 'P57W', 'P57Y', 'P57F', 'P57C', 'V58Q', 'V58E', 'V58N', 'V58H', 'V58D', 'V58R', 'V58K', 'V58T', 'V58S', 'V58A', 'V58G', 'V58M', 'V58L', 'V58I', 'V58W', 'V58Y', 'V58F', 'V58P', 'V58C', 'T14C'], 'prott5': tensor([[[-1.2809e-01, -3.4372e-01, -1.7375e-01,  ..., -2.9750e-02,\n",
      "          -1.6575e-01, -1.3848e-01],\n",
      "         [-1.0785e-01, -9.3911e-02, -1.7017e-01,  ...,  3.2915e-02,\n",
      "          -3.1065e-01,  4.3001e-02],\n",
      "         [-2.0858e-01,  4.8382e-02, -3.7936e-01,  ...,  1.9574e-01,\n",
      "          -1.1604e-01, -1.5309e-02],\n",
      "         ...,\n",
      "         [ 7.1865e-02,  1.0665e-01,  2.8578e-01,  ..., -3.0954e-02,\n",
      "           9.2807e-02, -2.3642e-01],\n",
      "         [ 9.2466e-02,  1.8047e-01,  1.5232e-02,  ..., -3.0748e-01,\n",
      "           1.3015e-01,  8.1892e-03],\n",
      "         [-6.3635e-02,  1.5185e-01,  1.7022e-01,  ..., -2.7657e-01,\n",
      "           2.4232e-02, -2.8669e-01]],\n",
      "\n",
      "        [[-1.2809e-01, -3.4372e-01, -1.7375e-01,  ..., -2.9750e-02,\n",
      "          -1.6575e-01, -1.3848e-01],\n",
      "         [-1.0785e-01, -9.3911e-02, -1.7017e-01,  ...,  3.2915e-02,\n",
      "          -3.1065e-01,  4.3001e-02],\n",
      "         [-2.0858e-01,  4.8382e-02, -3.7936e-01,  ...,  1.9574e-01,\n",
      "          -1.1604e-01, -1.5309e-02],\n",
      "         ...,\n",
      "         [ 7.1865e-02,  1.0665e-01,  2.8578e-01,  ..., -3.0954e-02,\n",
      "           9.2807e-02, -2.3642e-01],\n",
      "         [ 9.2466e-02,  1.8047e-01,  1.5232e-02,  ..., -3.0748e-01,\n",
      "           1.3015e-01,  8.1892e-03],\n",
      "         [-6.3635e-02,  1.5185e-01,  1.7022e-01,  ..., -2.7657e-01,\n",
      "           2.4232e-02, -2.8669e-01]],\n",
      "\n",
      "        [[-1.2809e-01, -3.4372e-01, -1.7375e-01,  ..., -2.9750e-02,\n",
      "          -1.6575e-01, -1.3848e-01],\n",
      "         [-1.0785e-01, -9.3911e-02, -1.7017e-01,  ...,  3.2915e-02,\n",
      "          -3.1065e-01,  4.3001e-02],\n",
      "         [-2.0858e-01,  4.8382e-02, -3.7936e-01,  ...,  1.9574e-01,\n",
      "          -1.1604e-01, -1.5309e-02],\n",
      "         ...,\n",
      "         [ 7.1865e-02,  1.0665e-01,  2.8578e-01,  ..., -3.0954e-02,\n",
      "           9.2807e-02, -2.3642e-01],\n",
      "         [ 9.2466e-02,  1.8047e-01,  1.5232e-02,  ..., -3.0748e-01,\n",
      "           1.3015e-01,  8.1892e-03],\n",
      "         [-6.3635e-02,  1.5185e-01,  1.7022e-01,  ..., -2.7657e-01,\n",
      "           2.4232e-02, -2.8669e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1502e-01, -3.3846e-01, -1.8809e-01,  ..., -3.2539e-02,\n",
      "          -1.0473e-01, -1.1050e-01],\n",
      "         [-4.6769e-02, -2.8336e-02, -1.5179e-01,  ..., -1.6478e-02,\n",
      "          -3.3333e-01,  6.8049e-02],\n",
      "         [-1.7217e-01,  1.2653e-01, -3.5918e-01,  ...,  1.6921e-01,\n",
      "          -9.5983e-02, -4.6482e-02],\n",
      "         ...,\n",
      "         [ 3.9545e-02,  1.4511e-01,  1.5102e-01,  ..., -1.5597e-01,\n",
      "           1.1141e-01, -3.6299e-02],\n",
      "         [ 4.8355e-02,  1.5911e-01,  5.9325e-02,  ..., -2.6469e-01,\n",
      "           1.5431e-01,  6.2564e-02],\n",
      "         [-6.8564e-02,  1.3810e-04, -2.4773e-02,  ..., -1.1331e-01,\n",
      "          -9.5271e-03, -7.3847e-02]],\n",
      "\n",
      "        [[-1.6321e-01, -3.5389e-01, -2.1527e-01,  ..., -2.5484e-02,\n",
      "          -1.3440e-01, -1.2543e-01],\n",
      "         [-7.9361e-02, -3.7657e-02, -1.8016e-01,  ..., -9.6364e-03,\n",
      "          -3.2186e-01,  7.8623e-02],\n",
      "         [-1.6326e-01,  1.1996e-01, -3.7766e-01,  ...,  1.6515e-01,\n",
      "          -1.1658e-01, -1.5163e-02],\n",
      "         ...,\n",
      "         [ 1.2579e-01,  1.9571e-01,  1.3664e-01,  ..., -1.5319e-01,\n",
      "           8.0483e-02, -3.8666e-02],\n",
      "         [ 7.4061e-02,  2.4399e-01,  2.4397e-02,  ..., -2.5713e-01,\n",
      "           6.4242e-03,  9.9535e-03],\n",
      "         [ 6.3181e-02,  2.6899e-01,  1.9011e-01,  ..., -3.4480e-01,\n",
      "          -1.0396e-02, -2.5372e-01]],\n",
      "\n",
      "        [[-1.4418e-01, -3.4458e-01, -2.0770e-01,  ..., -2.6706e-02,\n",
      "          -1.4715e-01, -1.0512e-01],\n",
      "         [-9.0270e-02, -4.6011e-02, -1.6961e-01,  ..., -1.7358e-02,\n",
      "          -3.1836e-01,  8.4880e-02],\n",
      "         [-1.6381e-01,  1.2049e-01, -3.6943e-01,  ...,  1.7146e-01,\n",
      "          -8.8395e-02, -7.0140e-03],\n",
      "         ...,\n",
      "         [ 1.2780e-01,  2.1514e-01,  1.6505e-01,  ..., -1.1103e-01,\n",
      "           7.2832e-02, -7.7808e-02],\n",
      "         [ 9.0270e-02,  2.0499e-01, -6.2847e-03,  ..., -3.1541e-01,\n",
      "           1.0321e-01,  2.4932e-02],\n",
      "         [-8.0075e-02,  1.7698e-01,  1.1000e-01,  ..., -2.4387e-01,\n",
      "          -7.2345e-02, -2.5225e-01]]]), 'coords': tensor([[[ 3.8300e+00,  6.5840e+00,  1.2265e+01],\n",
      "         [ 2.8180e+00,  6.0380e+00,  1.1334e+01],\n",
      "         [ 2.2560e+00,  7.2120e+00,  1.0563e+01],\n",
      "         [ 1.6950e+00,  5.2880e+00,  1.2077e+01]],\n",
      "\n",
      "        [[ 2.4310e+00,  7.2460e+00,  9.2450e+00],\n",
      "         [ 1.9420e+00,  8.3520e+00,  8.4080e+00],\n",
      "         [ 5.8700e-01,  7.9590e+00,  7.8380e+00],\n",
      "         [ 2.9380e+00,  8.7070e+00,  7.2930e+00]],\n",
      "\n",
      "        [[-4.3300e-01,  8.7740e+00,  8.1070e+00],\n",
      "         [-1.7880e+00,  8.5580e+00,  7.6090e+00],\n",
      "         [-1.9960e+00,  9.3220e+00,  6.3110e+00],\n",
      "         [-2.8340e+00,  8.9760e+00,  8.6550e+00]],\n",
      "\n",
      "        [[-2.7390e+00,  8.7100e+00,  5.4020e+00],\n",
      "         [-3.1000e+00,  9.2850e+00,  4.1170e+00],\n",
      "         [-4.6140e+00,  9.2280e+00,  3.9170e+00],\n",
      "         [-2.3360e+00,  8.5560e+00,  3.0080e+00]],\n",
      "\n",
      "        [[-5.1440e+00,  1.0121e+01,  3.0860e+00],\n",
      "         [-6.5610e+00,  1.0189e+01,  2.7170e+00],\n",
      "         [-6.7250e+00,  1.0076e+01,  1.2060e+00],\n",
      "         [-7.2170e+00,  1.1461e+01,  3.2900e+00]],\n",
      "\n",
      "        [[-7.7120e+00,  9.3000e+00,  7.6000e-01],\n",
      "         [-8.1050e+00,  9.2090e+00, -6.4100e-01],\n",
      "         [-8.6940e+00,  1.0532e+01, -1.1500e+00],\n",
      "         [-9.0890e+00,  8.0500e+00, -8.2400e-01]],\n",
      "\n",
      "        [[-8.1250e+00,  1.1045e+01, -2.2360e+00],\n",
      "         [-8.5700e+00,  1.2245e+01, -2.9430e+00],\n",
      "         [-9.7180e+00,  1.1951e+01, -3.9230e+00],\n",
      "         [-7.3630e+00,  1.2838e+01, -3.6920e+00]],\n",
      "\n",
      "        [[-9.7950e+00,  1.0709e+01, -4.4080e+00],\n",
      "         [-1.0736e+01,  1.0224e+01, -5.4200e+00],\n",
      "         [-1.1202e+01,  8.8020e+00, -5.0840e+00],\n",
      "         [-1.0065e+01,  1.0230e+01, -6.8060e+00]],\n",
      "\n",
      "        [[-1.2258e+01,  8.3500e+00, -5.7530e+00],\n",
      "         [-1.2666e+01,  6.9440e+00, -5.7410e+00],\n",
      "         [-1.1715e+01,  6.1170e+00, -6.6180e+00],\n",
      "         [-1.4115e+01,  6.8010e+00, -6.2370e+00]],\n",
      "\n",
      "        [[-1.1496e+01,  4.8580e+00, -6.2530e+00],\n",
      "         [-1.0695e+01,  3.9170e+00, -7.0260e+00],\n",
      "         [-1.1304e+01,  2.5150e+00, -6.9580e+00],\n",
      "         [-9.2550e+00,  3.9280e+00, -6.5050e+00]],\n",
      "\n",
      "        [[-1.1423e+01,  1.8730e+00, -8.1170e+00],\n",
      "         [-1.1854e+01,  4.8300e-01, -8.2560e+00],\n",
      "         [-1.0630e+01, -3.7700e-01, -8.5840e+00],\n",
      "         [-1.2954e+01,  4.0500e-01, -9.3280e+00]],\n",
      "\n",
      "        [[-1.0415e+01, -1.4230e+00, -7.7840e+00],\n",
      "         [-9.3020e+00, -2.3580e+00, -7.9050e+00],\n",
      "         [-9.2200e+00, -2.9520e+00, -9.3170e+00],\n",
      "         [-9.4730e+00, -3.4620e+00, -6.8540e+00]],\n",
      "\n",
      "        [[-8.0060e+00, -3.0010e+00, -9.8770e+00],\n",
      "         [-7.7490e+00, -3.5510e+00, -1.1220e+01],\n",
      "         [-7.0790e+00, -4.9170e+00, -1.1181e+01],\n",
      "         [-6.8980e+00, -2.5610e+00, -1.2013e+01]],\n",
      "\n",
      "        [[-6.5620e+00, -5.3060e+00, -1.0022e+01],\n",
      "         [-5.9580e+00, -6.6100e+00, -9.7540e+00],\n",
      "         [-6.4880e+00, -7.1620e+00, -8.4310e+00],\n",
      "         [-4.4190e+00, -6.5420e+00, -9.7470e+00]],\n",
      "\n",
      "        [[-6.2460e+00, -8.4450e+00, -8.1590e+00],\n",
      "         [-6.6250e+00, -9.0720e+00, -6.8830e+00],\n",
      "         [-5.8250e+00, -8.5250e+00, -5.6880e+00],\n",
      "         [-6.4550e+00, -1.0600e+01, -6.9800e+00]],\n",
      "\n",
      "        [[-4.6680e+00, -7.9050e+00, -5.9420e+00],\n",
      "         [-3.7930e+00, -7.3370e+00, -4.9130e+00],\n",
      "         [-4.0850e+00, -5.8470e+00, -4.6380e+00],\n",
      "         [-2.3240e+00, -7.5410e+00, -5.3250e+00]],\n",
      "\n",
      "        [[-4.9560e+00, -5.2090e+00, -5.4260e+00],\n",
      "         [-5.3340e+00, -3.8020e+00, -5.2730e+00],\n",
      "         [-6.4740e+00, -3.6350e+00, -4.2570e+00],\n",
      "         [-5.8230e+00, -3.2060e+00, -6.5980e+00]],\n",
      "\n",
      "        [[-6.4830e+00, -2.5190e+00, -3.5260e+00],\n",
      "         [-7.6580e+00, -2.1170e+00, -2.7490e+00],\n",
      "         [-8.6200e+00, -1.2930e+00, -3.6040e+00],\n",
      "         [-7.2390e+00, -1.3340e+00, -1.4960e+00]],\n",
      "\n",
      "        [[-9.9230e+00, -1.5520e+00, -3.4850e+00],\n",
      "         [-1.0962e+01, -5.9900e-01, -3.9060e+00],\n",
      "         [-1.1295e+01,  3.4000e-01, -2.7500e+00],\n",
      "         [-1.2243e+01, -1.3060e+00, -4.3440e+00]],\n",
      "\n",
      "        [[-1.1515e+01,  1.6240e+00, -3.0260e+00],\n",
      "         [-1.1810e+01,  2.6080e+00, -1.9870e+00],\n",
      "         [-1.2593e+01,  3.8120e+00, -2.4940e+00],\n",
      "         [-1.0512e+01,  3.0620e+00, -1.3210e+00]],\n",
      "\n",
      "        [[-1.3216e+01,  4.5160e+00, -1.5530e+00],\n",
      "         [-1.3965e+01,  5.7370e+00, -1.8350e+00],\n",
      "         [-1.3176e+01,  6.9720e+00, -1.3950e+00],\n",
      "         [-1.5348e+01,  5.6720e+00, -1.1770e+00]],\n",
      "\n",
      "        [[-1.3436e+01,  8.1100e+00, -2.0360e+00],\n",
      "         [-1.2892e+01,  9.4090e+00, -1.6480e+00],\n",
      "         [-1.3133e+01,  9.6730e+00, -1.6000e-01],\n",
      "         [-1.3538e+01,  1.0487e+01, -2.5210e+00]],\n",
      "\n",
      "        [[-1.2086e+01,  1.0121e+01,  5.2900e-01],\n",
      "         [-1.2102e+01,  1.0407e+01,  1.9630e+00],\n",
      "         [-1.1739e+01,  9.2140e+00,  2.8500e+00],\n",
      "         [-1.1392e+01,  1.1209e+01,  2.1660e+00]],\n",
      "\n",
      "        [[-1.1618e+01,  8.0090e+00,  2.2890e+00],\n",
      "         [-1.1115e+01,  6.8430e+00,  3.0100e+00],\n",
      "         [-9.6690e+00,  7.0600e+00,  3.4800e+00],\n",
      "         [-1.1274e+01,  5.6040e+00,  2.1260e+00]],\n",
      "\n",
      "        [[-9.3370e+00,  6.5670e+00,  4.6800e+00],\n",
      "         [-8.0220e+00,  6.7690e+00,  5.3010e+00],\n",
      "         [-7.1950e+00,  5.4970e+00,  5.2770e+00],\n",
      "         [-8.1370e+00,  7.3030e+00,  6.7310e+00]],\n",
      "\n",
      "        [[-5.8970e+00,  5.6700e+00,  5.0710e+00],\n",
      "         [-4.9400e+00,  4.5830e+00,  4.9370e+00],\n",
      "         [-3.7620e+00,  4.7540e+00,  5.8810e+00],\n",
      "         [-4.4560e+00,  4.4970e+00,  3.4880e+00]],\n",
      "\n",
      "        [[-3.2780e+00,  3.6270e+00,  6.3910e+00],\n",
      "         [-1.9200e+00,  3.5040e+00,  6.8940e+00],\n",
      "         [-1.0380e+00,  2.9720e+00,  5.7640e+00],\n",
      "         [-1.9250e+00,  2.5780e+00,  8.1170e+00]],\n",
      "\n",
      "        [[-1.1000e-02,  3.7230e+00,  5.3700e+00],\n",
      "         [ 9.5800e-01,  3.2520e+00,  4.3730e+00],\n",
      "         [ 1.9260e+00,  2.2640e+00,  5.0350e+00],\n",
      "         [ 1.6690e+00,  4.4420e+00,  3.6990e+00]],\n",
      "\n",
      "        [[ 2.0240e+00,  1.0610e+00,  4.4670e+00],\n",
      "         [ 2.8890e+00, -2.9000e-02,  4.9230e+00],\n",
      "         [ 4.2100e+00, -3.8000e-02,  4.1510e+00],\n",
      "         [ 2.1670e+00, -1.3800e+00,  4.7590e+00]],\n",
      "\n",
      "        [[ 4.1470e+00,  1.5700e-01,  2.8300e+00],\n",
      "         [ 5.3160e+00,  2.4400e-01,  1.9640e+00],\n",
      "         [ 5.1030e+00,  1.2630e+00,  8.3400e-01],\n",
      "         [ 5.6510e+00, -1.1570e+00,  1.4230e+00]],\n",
      "\n",
      "        [[ 6.0030e+00,  2.2410e+00,  7.4600e-01],\n",
      "         [ 6.0460e+00,  3.2560e+00, -3.1300e-01],\n",
      "         [ 7.4580e+00,  3.4420e+00, -8.7600e-01],\n",
      "         [ 5.4850e+00,  4.5820e+00,  2.1100e-01]],\n",
      "\n",
      "        [[ 8.3160e+00,  2.4180e+00, -7.9100e-01],\n",
      "         [ 9.7230e+00,  2.5460e+00, -1.1820e+00],\n",
      "         [ 9.9270e+00,  2.5690e+00, -2.6940e+00],\n",
      "         [ 1.0571e+01,  1.4380e+00, -5.4600e-01]],\n",
      "\n",
      "        [[ 9.0340e+00,  1.9430e+00, -3.4660e+00],\n",
      "         [ 9.2230e+00,  1.7350e+00, -4.9030e+00],\n",
      "         [ 7.9180e+00,  1.8920e+00, -5.6910e+00],\n",
      "         [ 9.8430e+00,  3.5000e-01, -5.1660e+00]],\n",
      "\n",
      "        [[ 7.9950e+00,  2.6480e+00, -6.7890e+00],\n",
      "         [ 6.9320e+00,  2.7610e+00, -7.7840e+00],\n",
      "         [ 5.7590e+00,  3.6680e+00, -7.4040e+00],\n",
      "         [ 7.3570e+00,  3.1390e+00, -8.7140e+00]],\n",
      "\n",
      "        [[ 4.7780e+00,  3.6920e+00, -8.3060e+00],\n",
      "         [ 3.5730e+00,  4.5190e+00, -8.1900e+00],\n",
      "         [ 2.4510e+00,  3.8340e+00, -7.3930e+00],\n",
      "         [ 3.0800e+00,  4.9090e+00, -9.5920e+00]],\n",
      "\n",
      "        [[ 2.6540e+00,  2.5820e+00, -6.9690e+00],\n",
      "         [ 1.7040e+00,  1.7780e+00, -6.2000e+00],\n",
      "         [ 2.2660e+00,  1.5000e+00, -4.8170e+00],\n",
      "         [ 1.3890e+00,  4.6900e-01, -6.9250e+00]],\n",
      "\n",
      "        [[ 1.5520e+00,  1.9350e+00, -3.7880e+00],\n",
      "         [ 1.9730e+00,  1.7630e+00, -2.4020e+00],\n",
      "         [ 1.1540e+00,  6.7400e-01, -1.7360e+00],\n",
      "         [ 1.8630e+00,  3.0920e+00, -1.6570e+00]],\n",
      "\n",
      "        [[ 1.8060e+00, -1.4000e-01, -9.1300e-01],\n",
      "         [ 1.1140e+00, -1.0780e+00, -3.9000e-02],\n",
      "         [ 5.1600e-01, -2.9400e-01,  1.1300e+00],\n",
      "         [ 2.0790e+00, -2.1590e+00,  4.5100e-01]],\n",
      "\n",
      "        [[-7.9000e-01, -4.2500e-01,  1.3160e+00],\n",
      "         [-1.5420e+00,  3.1200e-01,  2.3090e+00],\n",
      "         [-2.5460e+00, -5.9200e-01,  3.0150e+00],\n",
      "         [-2.2290e+00,  1.4890e+00,  1.6140e+00]],\n",
      "\n",
      "        [[-2.9010e+00, -2.0900e-01,  4.2400e+00],\n",
      "         [-4.0090e+00, -7.9400e-01,  4.9870e+00],\n",
      "         [-5.1440e+00,  2.1300e-01,  5.0950e+00],\n",
      "         [-3.5060e+00, -1.2710e+00,  6.3480e+00]],\n",
      "\n",
      "        [[-6.3390e+00, -1.5700e-01,  4.6430e+00],\n",
      "         [-7.5450e+00,  6.4600e-01,  4.8570e+00],\n",
      "         [-7.8860e+00,  6.9500e-01,  6.3470e+00],\n",
      "         [-8.7350e+00,  9.9000e-02,  4.0640e+00]],\n",
      "\n",
      "        [[-8.1540e+00,  1.8950e+00,  6.8650e+00],\n",
      "         [-8.6730e+00,  2.0790e+00,  8.2230e+00],\n",
      "         [-1.0194e+01,  1.8860e+00,  8.3150e+00],\n",
      "         [-8.2580e+00,  3.4570e+00,  8.7630e+00]],\n",
      "\n",
      "        [[-1.0884e+01,  1.7490e+00,  7.1800e+00],\n",
      "         [-1.2331e+01,  1.5060e+00,  7.1160e+00],\n",
      "         [-1.2631e+01,  1.2000e-02,  7.0680e+00],\n",
      "         [-1.2947e+01,  2.1970e+00,  5.8930e+00]],\n",
      "\n",
      "        [[-1.1994e+01, -7.2200e-01,  6.1500e+00],\n",
      "         [-1.2233e+01, -2.1630e+00,  5.9460e+00],\n",
      "         [-1.1247e+01, -3.0340e+00,  6.7240e+00],\n",
      "         [-1.2192e+01, -2.5370e+00,  4.4530e+00]],\n",
      "\n",
      "        [[-1.0063e+01, -2.5020e+00,  7.0470e+00],\n",
      "         [-8.9770e+00, -3.2450e+00,  7.6860e+00],\n",
      "         [-8.1270e+00, -4.0760e+00,  6.7220e+00],\n",
      "         [-8.3200e+00, -2.5380e+00,  8.1930e+00]],\n",
      "\n",
      "        [[-8.5030e+00, -4.1300e+00,  5.4410e+00],\n",
      "         [-7.8230e+00, -4.8630e+00,  4.3690e+00],\n",
      "         [-6.4940e+00, -4.2070e+00,  3.9810e+00],\n",
      "         [-8.7320e+00, -4.9710e+00,  3.1330e+00]],\n",
      "\n",
      "        [[-5.5800e+00, -5.0240e+00,  3.4590e+00],\n",
      "         [-4.2710e+00, -4.6040e+00,  2.9500e+00],\n",
      "         [-4.1850e+00, -4.9090e+00,  1.4620e+00],\n",
      "         [-3.1220e+00, -5.3100e+00,  3.6820e+00]],\n",
      "\n",
      "        [[-3.5960e+00, -3.9950e+00,  6.9900e-01],\n",
      "         [-3.3220e+00, -4.1680e+00, -7.2400e-01],\n",
      "         [-2.6560e+00, -2.9280e+00, -1.3100e+00],\n",
      "         [-2.6620e+00, -5.0220e+00, -8.7500e-01]],\n",
      "\n",
      "        [[-2.5270e+00, -2.8910e+00, -2.6300e+00],\n",
      "         [-1.9090e+00, -1.7870e+00, -3.3480e+00],\n",
      "         [-2.9060e+00, -6.7600e-01, -3.6750e+00],\n",
      "         [-1.1820e+00, -2.2970e+00, -4.5930e+00]],\n",
      "\n",
      "        [[-2.4380e+00,  5.6500e-01, -3.5670e+00],\n",
      "         [-3.1710e+00,  1.7670e+00, -3.9670e+00],\n",
      "         [-2.2960e+00,  2.6530e+00, -4.8600e+00],\n",
      "         [-3.7010e+00,  2.5480e+00, -2.7420e+00]],\n",
      "\n",
      "        [[-2.8750e+00,  3.3840e+00, -5.8270e+00],\n",
      "         [-2.1190e+00,  4.3430e+00, -6.6170e+00],\n",
      "         [-1.7480e+00,  5.5570e+00, -5.7530e+00],\n",
      "         [-3.0150e+00,  4.6750e+00, -7.8110e+00]],\n",
      "\n",
      "        [[-4.5300e-01,  5.8320e+00, -5.6300e+00],\n",
      "         [ 1.0600e-01,  6.8730e+00, -4.7550e+00],\n",
      "         [-4.2300e-01,  8.2800e+00, -5.0540e+00],\n",
      "         [ 1.6270e+00,  6.8730e+00, -4.8870e+00]],\n",
      "\n",
      "        [[-7.4900e-01,  8.5710e+00, -6.3150e+00],\n",
      "         [-1.3110e+00,  9.8520e+00, -6.7450e+00],\n",
      "         [-2.8120e+00,  1.0018e+01, -6.4290e+00],\n",
      "         [-1.0030e+00,  1.0066e+01, -8.2370e+00]],\n",
      "\n",
      "        [[-3.4660e+00,  9.0000e+00, -5.8600e+00],\n",
      "         [-4.8550e+00,  9.0790e+00, -5.3910e+00],\n",
      "         [-4.9500e+00,  9.4440e+00, -3.9160e+00],\n",
      "         [-5.6120e+00,  7.7720e+00, -5.6640e+00]],\n",
      "\n",
      "        [[-3.8210e+00,  9.5780e+00, -3.2210e+00],\n",
      "         [-3.7910e+00,  9.8800e+00, -1.7960e+00],\n",
      "         [-2.9180e+00,  1.1089e+01, -1.4780e+00],\n",
      "         [-3.3890e+00,  8.6520e+00, -9.6500e-01]],\n",
      "\n",
      "        [[-3.2060e+00,  1.1740e+01, -3.5500e-01],\n",
      "         [-2.3590e+00,  1.2778e+01,  2.2500e-01],\n",
      "         [-2.1900e+00,  1.2544e+01,  1.7320e+00],\n",
      "         [-2.9720e+00,  1.4151e+01, -6.2000e-02]],\n",
      "\n",
      "        [[-1.0880e+00,  1.3012e+01,  2.3510e+00],\n",
      "         [-9.5500e-01,  1.2991e+01,  3.8020e+00],\n",
      "         [-2.1470e+00,  1.3691e+01,  4.4660e+00],\n",
      "         [ 3.6400e-01,  1.3704e+01,  4.1180e+00]],\n",
      "\n",
      "        [[-2.6390e+00,  1.3117e+01,  5.5680e+00],\n",
      "         [-3.6380e+00,  1.3761e+01,  6.4440e+00],\n",
      "         [-3.0150e+00,  1.4932e+01,  7.1930e+00],\n",
      "         [-4.2690e+00,  1.2759e+01,  7.4220e+00]]]), 'one_hot': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'delta_g': tensor([2.5602, 2.5827, 2.5673,  ..., 1.5238, 2.8126, 4.2234]), 'masks': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1A0N\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n",
      "torch.Size([58, 1093])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1A32\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n",
      "torch.Size([63, 1093])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1AOY\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n",
      "torch.Size([69, 1093])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1B7J\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n",
      "torch.Size([64, 1093])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1BK2\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n",
      "torch.Size([56, 1093])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1BNZ\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n",
      "torch.Size([62, 1093])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1CSQ\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n",
      "torch.Size([67, 1093])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coords_tensor = torch.load(os.path.join(protein_dir, COORDS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  delta_g_tensor = torch.load(os.path.join(protein_dir, DELTA_G))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_tensor = torch.load(os.path.join(protein_dir, MASKS))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3631266535.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  one_hot_tensor = torch.load(os.path.join(protein_dir, ONE_HOT))\n",
      "C:\\Users\\darea\\AppData\\Local\\Temp\\ipykernel_19684\\3289470293.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embedding_tensor = torch.load(filename, map_location=torch.device('cpu'))  # Ensure loading on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 1E0L\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "torch.Size([37, 1093])\n",
      "avg deltaG for each protein: [-1.6611787, 5.7336416, 2.7149787, 1.0901723, 0.77602965, 4.166648, 3.418411, 0.31410328]\n",
      "avg DDG for each protein: [0.2516402, 7.6464605, 4.6277976, 3.0029912, 2.6888485, 6.079467, 5.33123, 2.2269223]\n",
      "Protein 1 correlation: 0.08719221182283603\n",
      "Protein 2 correlation: 0.11964336916290814\n",
      "Protein 3 correlation: 0.2366858212367492\n",
      "Protein 4 correlation: -0.4249438789139504\n",
      "Protein 5 correlation: 0.12397388399105758\n",
      "Protein 6 correlation: 0.24762197036204237\n",
      "Protein 7 correlation: 0.07899024234851651\n",
      "Protein 8 correlation: -0.10790249901645739\n"
     ]
    }
   ],
   "source": [
    "protein_dataset = MutationDataset(TENSOR_ROOT, MUTATIONS_ROOT, one_mut = True)\n",
    "#create a DataLoader\n",
    "#protein_dataloader = DataLoader(protein_dataset, batch_size=1, shuffle=True)\n",
    "print(protein_dataset[0])\n",
    "avg_dGs = []\n",
    "avg_ddGs = []\n",
    "correlations = []\n",
    "for mutations_data in protein_dataset:\n",
    "    #calculate wt dG\n",
    "    print(f\"Protein: {mutations_data['name']}\")\n",
    "    wt_index = find_wt_index(mutations_data)\n",
    "    seq_one_hot = mutations_data['one_hot'][wt_index]\n",
    "    proT5_emb = mutations_data['prott5'][wt_index]\n",
    "    mask = mutations_data['masks'][0]\n",
    "    coords_tensor = mutations_data['coords']\n",
    "    protein_graph = get_graph( coords_tensor ,seq_one_hot, proT5_emb,mask)\n",
    "    protein_unfolded_graph = get_unfolded_graph( coords_tensor ,seq_one_hot, proT5_emb,mask)\n",
    "    pred_mut_dG = []\n",
    "    pred_mut_ddG = []\n",
    "    for i in range(1,NUMBER_OF_VARIANTS):\n",
    "        if i == wt_index:\n",
    "            continue\n",
    "        seq_one_hot = mutations_data['one_hot'][i]\n",
    "        proT5_emb = mutations_data['prott5'][i]\n",
    "        mask = mutations_data['masks'][0]\n",
    "        coords_tensor = mutations_data['coords']\n",
    "        protein_graph = get_graph( coords_tensor ,seq_one_hot, proT5_emb, mask)\n",
    "        protein_unfolded_graph = get_unfolded_graph( coords_tensor ,seq_one_hot, proT5_emb,mask)\n",
    "        pred_deltaG = calculate_dG(protein_graph, protein_unfolded_graph)\n",
    "        pred_mut_dG.append(pred_deltaG)\n",
    "        pred_mut_ddG.append(pred_deltaG-pred_wt_deltaG)\n",
    "\n",
    "    #average dG\n",
    "    avg_dG = np.mean(pred_mut_dG)\n",
    "    avg_dGs.append(avg_dG)\n",
    "    #average ddG\n",
    "    avg_ddG = avg_dG-pred_wt_deltaG\n",
    "    avg_ddGs.append(avg_ddG)\n",
    "    #calculate the correlation \n",
    "    true_dG = mutations_data['delta_g'][1:NUMBER_OF_VARIANTS]\n",
    "    correlation = np.corrcoef(pred_mut_dG,true_dG)\n",
    "    correlations.append(correlation)\n",
    "    \n",
    "print(f\"avg deltaG for each protein: {avg_dGs}\") \n",
    "\n",
    "print(f\"avg DDG for each protein: {avg_ddGs}\")\n",
    "\n",
    "# Print the correlation for each protein \n",
    "for idx, corr in enumerate(correlations):\n",
    "    print(f\"Protein {idx + 1} correlation: {corr[0, 1]}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProteinDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, tensor_root_dir, mutations_root_dir):\n",
    "#         self.tensor_root_dir = tensor_root_dir\n",
    "#         self.mutations_root_dir = mutations_root_dir\n",
    "#         self.protein_dirs = os.listdir(self.tensor_root_dir)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.protein_dirs)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         protein_dir = os.path.join(self.tensor_root_dir, self.protein_dirs[idx])\n",
    "#         mutations_path = os.path.join(self.mutations_root_dir, f\"{self.protein_dirs[idx]}.csv\")\n",
    "        \n",
    "#         mutations = pd.read_csv(mutations_path)\n",
    "#         coords_tensor = torch.load(os.path.join(protein_dir, \"coords_tensor.pt\"), map_location='cpu')\n",
    "#         delta_g_tensor = torch.load(os.path.join(protein_dir, \"deltaG.pt\"), map_location='cpu')\n",
    "#         mask_tensor = torch.load(os.path.join(protein_dir, \"mask_tensor.pt\"), map_location='cpu')\n",
    "#         one_hot_tensor = torch.load(os.path.join(protein_dir, \"one_hot_encodings.pt\"), map_location='cpu')\n",
    "#         prott5_tensor = torch.load(os.path.join(protein_dir, \"prott5_embeddings/prott5_embedding_0.pt\"), map_location='cpu')\n",
    "\n",
    "#         return {\n",
    "#             'name': self.protein_dirs[idx],\n",
    "#             'mutations': mutations.to_dict(orient=\"records\"),  # Convert DataFrame to a list of dicts\n",
    "#             'coords': coords_tensor,\n",
    "#             'one_hot': one_hot_tensor,\n",
    "#             'delta_g': delta_g_tensor,\n",
    "#             'masks': mask_tensor,\n",
    "#             'prott5': prott5_tensor\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from torch.utils.data import DataLoader\n",
    "# from Utils.train_utils import get_graph, get_unfolded_graph\n",
    "# from model.hydro_net import PEM\n",
    "# from model.model_cfg import CFG\n",
    "\n",
    "# # Constants\n",
    "# NUMBER_OF_VARIANTS = 128\n",
    "# NANO_TO_ANGSTROM = 0.1\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# REG_LAMBDA = 0.01  # Same as fine-tuning model\n",
    "\n",
    "# # Load Model\n",
    "# # Import the model\n",
    "# model = PEM(layers=CFG.num_layers,gaussian_coef=CFG.gaussian_coef).to(CFG.device)\n",
    "# # Upload model weights\n",
    "# CFG.model_path = '../data/Trained_models/'\n",
    "# epoch = 25\n",
    "# model_dict = torch.load(CFG.model_path+f\"{epoch}_final_model.pt\", map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(model_dict['model_state_dict'])\n",
    "# model.eval()\n",
    "\n",
    "# # Normalize batch function\n",
    "# def normalize_batch(batch):\n",
    "#     batch['one_hot'] = batch['one_hot'][:, :, :, :-1]  # Remove last channel\n",
    "#     batch['coords'] = batch['coords'] * NANO_TO_ANGSTROM  # Scale coordinates\n",
    "#     return batch\n",
    "\n",
    "\n",
    "# # Load dataset & dataloader\n",
    "# protein_dataset = ProteinDataset(\"mutation_data/tensors\", \"mutation_data/mutations\")\n",
    "# protein_dataloader = DataLoader(protein_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# # Function to compute deltaG\n",
    "# def calculate_dG(protein_graph, protein_unfolded_graph):\n",
    "#     with torch.no_grad():\n",
    "#         Gf = model(protein_graph.unsqueeze(0)).cpu().numpy()[0]\n",
    "#         Gu = model(protein_unfolded_graph.unsqueeze(0)).cpu().numpy()[0]\n",
    "#         return Gu - Gf\n",
    "\n",
    "# # Evaluation loop\n",
    "# avg_dGs, avg_ddGs, correlations = [], [], []\n",
    "# for batch in protein_dataloader:\n",
    "#     batch = normalize_batch(batch)\n",
    "    \n",
    "#     # Compute wildtype energy\n",
    "#     wt_index = 0  # Assuming wildtype is first in the list\n",
    "#     protein_graph = get_graph(batch['coords'], batch['one_hot'][wt_index], batch['prott5'][wt_index], batch['masks'])\n",
    "#     protein_unfolded_graph = get_unfolded_graph(batch['coords'], batch['one_hot'][wt_index], batch['prott5'][wt_index], batch['masks'])\n",
    "#     pred_wt_deltaG = calculate_dG(protein_graph, protein_unfolded_graph)\n",
    "\n",
    "#     # Compute mutation energies in batches\n",
    "#     pred_mut_dG, pred_mut_ddG = [], []\n",
    "#     true_dG = batch['delta_g'][1:NUMBER_OF_VARIANTS].cpu().numpy()  # True ΔG from dataset\n",
    "#     for i in range(1, NUMBER_OF_VARIANTS):\n",
    "#         protein_graph = get_graph(batch['coords'], batch['one_hot'][i], batch['prott5'][i], batch['masks'])\n",
    "#         protein_unfolded_graph = get_unfolded_graph(batch['coords'], batch['one_hot'][i], batch['prott5'][i], batch['masks'])\n",
    "#         pred_deltaG = calculate_dG(protein_graph, protein_unfolded_graph)\n",
    "#         pred_mut_dG.append(pred_deltaG)\n",
    "#         pred_mut_ddG.append(pred_deltaG - pred_wt_deltaG)\n",
    "\n",
    "#     # Compute averages\n",
    "#     avg_dG = np.mean(pred_mut_dG)\n",
    "#     avg_ddG = avg_dG - pred_wt_deltaG\n",
    "#     avg_dGs.append(avg_dG)\n",
    "#     avg_ddGs.append(avg_ddG)\n",
    "\n",
    "#     # Compute correlation\n",
    "#     pred_mut_dG = np.array(pred_mut_dG)\n",
    "#     mask = ~np.isnan(pred_mut_dG) & ~np.isnan(true_dG)  # Ensure no NaN values\n",
    "#     correlation = np.corrcoef(pred_mut_dG[mask], true_dG[mask])[0, 1]\n",
    "#     correlations.append(correlation)\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Avg deltaG for each protein: {avg_dGs}\")\n",
    "# print(f\"Avg DDG for each protein: {avg_ddGs}\")\n",
    "# for idx, corr in enumerate(correlations):\n",
    "#     print(f\"Protein {idx + 1} correlation: {corr:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
