{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference the results of the thrmodynamic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data_loader import fetch_dataloader,fetch_inference_loader\n",
    "from model.data_loader import params as data_params\n",
    "from model.model_cfg import CFG\n",
    "# from model.net import ProteinEnergyNet\n",
    "from model.hydro_net import PEM\n",
    "from train_utils import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import constants as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cs/casp15/Shahar/DeepPEF'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 393517\n"
     ]
    }
   ],
   "source": [
    "model = PEM(layers=CFG.num_layers,gaussian_coef=CFG.gaussian_coef).to(CFG.device)\n",
    "model.name = \"PEM-thermodynamic cycle\"\n",
    "# optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "optimizer = optim.SGD(model.parameters(), lr=CFG.lr)\n",
    "# Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./res/trianed_models-newDecoys/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./res/trianed_models-no_exdu_nosigmoid//best_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./res/trianed_models-no_exdu_nosigmoid//best_model.pt\"\n",
    "model,optimizer,epoch,loss,valid_loss = load_checkpoint(model_path,model,optimizer,device=CFG.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1A0N example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cb(crd_coords):\n",
    "        \"\"\"\n",
    "        Add the Cbeta atom to the coordinates\n",
    "        Args:\n",
    "            crd_coords (tensor): tensor of shape [n_residues,3,3]\n",
    "\n",
    "        Returns:\n",
    "            crd_coords: tensor shape [n_residues,4,3]\n",
    "        \"\"\"\n",
    "        # Get the coordinates of the backbone atoms\n",
    "        N, CA, C = crd_coords[:, 0], crd_coords[:, 1], crd_coords[:, 2]\n",
    "        # CB = CA + c1*(N-CA) + c2*(C-CA) + c3* (N-CA)x(C-CA)\n",
    "        CAmN = N - CA\n",
    "        # CAmN = CAmN / torch.sqrt(CAmN ** 2).sum(dim=2, keepdim=True)\n",
    "        CAmC = C - CA\n",
    "        # CAmC = CAmC / torch.sqrt(CAmC ** 2).sum(dim=2, keepdim=True)\n",
    "        ANxAC = torch.cross(CAmN, CAmC, dim=1)\n",
    "\n",
    "        A = torch.cat((CAmN.reshape(-1, 1), CAmC.reshape(-1, 1), ANxAC.reshape(-1, 1)), dim=1)\n",
    "        c = torch.tensor([0.5507, 0.5354, -0.5691]) / 100  # torch.tensor([1.1930, 1.2106, -2.7906]) #\n",
    "        b = (A @ c).reshape(-1,3)\n",
    "        CB = CA - b\n",
    "      \n",
    "        # Add Cbeta coordinates to existing coordinates array\n",
    "        crd_coords = torch.cat((crd_coords, CB.unsqueeze(1)), dim=1)\n",
    "        return crd_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = glob.glob('./data/casp12_data_30/train/*')\n",
    "item_path = './data/casp12_data_100/train/1A0N_2_B'\n",
    "# item_path = './data/casp12_data_100/train/1WR4_1_A'\n",
    "# item_path = './data/casp12_data_100/train/2B89_1_A'\n",
    "decoy_path = data_dir[np.random.randint(len(data_dir))]\n",
    "while decoy_path == item_path:\n",
    "    decoy_path = data_dir[np.random.randint(len(data_dir))]\n",
    "# load data\n",
    "id = torch.load(item_path + '/id.pt')\n",
    "crd_backbone = torch.tensor(torch.load(item_path + '/crd_backbone.pt'),dtype=torch.get_default_dtype()) #backbone coordinates N,Calpha,C\n",
    "crd_decoy = torch.tensor(torch.load(decoy_path + '/crd_backbone.pt'),dtype=torch.get_default_dtype()) #backbone coordinates N,Calpha,C\n",
    "\n",
    "mask = torch.load(item_path + '/mask.pt')\n",
    "mask_decoy = torch.load(decoy_path + '/mask.pt')\n",
    "# change to 1,0 mask\n",
    "mask = torch.tensor(np.where(np.array(list(mask))=='+',1,0))\n",
    "mask_decoy = torch.tensor(np.where(np.array(list(mask_decoy))=='+',1,0))\n",
    "# one hot encoding of the sequence\n",
    "seq_one_hot = torch.load(item_path + '/seq_one_hot.pt')\n",
    "seq = torch.load(item_path + '/seq.pt')\n",
    "seq_decoy = torch.load(decoy_path + '/seq.pt')\n",
    "proT5_emb = torch.load(item_path + '/proT5_emb.pt')\n",
    "# proT5_emb = torch.zeros((len(seq),1024)) # for testing\n",
    "ang = torch.tensor(torch.load(item_path + '/ang.pt'))\n",
    "ang_backbone = torch.clone(ang)[:,:3] #angles for the backbone phi, psi, omega\n",
    "# Add Cbeta atom to the coordinates\n",
    "crd_backbone = add_cb(crd_backbone)\n",
    "crd_decoy = add_cb(crd_decoy)\n",
    "# Convert to angstrom\n",
    "crd_backbone = crd_backbone * C.NANO_TO_ANGSTROM \n",
    "crd_decoy = crd_decoy * C.NANO_TO_ANGSTROM \n",
    "\n",
    "# ProT5 embedding for protein mutation\n",
    "proT5_mut = torch.load(item_path + '/proT5_emb_mut.pt')\n",
    "seq_mut =  torch.load(item_path + '/seq_mut.pt')\n",
    "# proT5_mut = torch.zeros((len(seq),1024)) # for testing\n",
    "# seq_mut = seq # for testing\n",
    "# unsqueeze the data and save it in a list\n",
    "data = id, crd_backbone.unsqueeze(0), mask.unsqueeze(0), seq_one_hot.unsqueeze(0), seq,ang_backbone.unsqueeze(0),ang.unsqueeze(0), proT5_emb.unsqueeze(0), proT5_mut.unsqueeze(0),[seq_mut],\\\n",
    "    crd_decoy.unsqueeze(0), mask_decoy.unsqueeze(0), [seq_decoy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 66]\n",
      "E A\n"
     ]
    }
   ],
   "source": [
    "s1 = seq\n",
    "s2 = seq_mut\n",
    "# get diffrent characters\n",
    "diff = []\n",
    "for i in range(len(s1)):\n",
    "    if s1[i] != s2[i]:\n",
    "        diff.append(i)\n",
    "print(diff)\n",
    "print(s1[diff[0]],s2[diff[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1A0N_2_B\n",
      "crd_backbone: torch.Size([1, 69, 4, 3])\n",
      "mask: torch.Size([1, 69])\n",
      "seq_one_hot: torch.Size([1, 69, 20])\n",
      "seq: GSTGVTLFVALYDYEARTEDDLSFHKGEKFQILNSSEGDWWEARSLTTGETGYIPSNYVAPVDSIQAEE\n",
      "ang_backbone: torch.Size([1, 69, 3])\n",
      "ang: torch.Size([1, 69, 12])\n",
      "proT5_emb: torch.Size([1, 69, 1024])\n",
      "proT5_mut: torch.Size([1, 69, 1024])\n",
      "seq_mut: 1\n",
      "crd_decoy: torch.Size([1, 135, 4, 3])\n",
      "mask_crd_decoy: torch.Size([1, 135])\n",
      "seq_crd_decoy: 1\n"
     ]
    }
   ],
   "source": [
    "def print_shapes(data):\n",
    "    id, crd_backbone, mask, seq_one_hot, seq,ang_backbone, ang,\\\n",
    "                proT5_emb, proT5_mut,seq_mut, crd_decoy, mask_crd_decoy, seq_crd_decoy = data\n",
    "    print(f\"id: {id}\")\n",
    "    print(f\"crd_backbone: {crd_backbone.shape}\")\n",
    "    print(f\"mask: {mask.shape}\")\n",
    "    print(f\"seq_one_hot: {seq_one_hot.shape}\")\n",
    "    print(f\"seq: {seq}\")\n",
    "    print(f\"ang_backbone: {ang_backbone.shape}\")\n",
    "    print(f\"ang: {ang.shape}\")\n",
    "    print(f\"proT5_emb: {proT5_emb.shape}\")\n",
    "    print(f\"proT5_mut: {proT5_mut.shape}\")\n",
    "    print(f\"seq_mut: {len(seq_mut)}\")\n",
    "    print(f\"crd_decoy: {crd_decoy.shape}\")\n",
    "    print(f\"mask_crd_decoy: {mask_crd_decoy.shape}\")\n",
    "    print(f\"seq_crd_decoy: {len(seq_crd_decoy)}\")\n",
    "    return\n",
    "print_shapes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1A0N_2_B\n",
      "crd_backbone: torch.Size([1, 500, 4, 3])\n",
      "mask: torch.Size([1, 500])\n",
      "seq_one_hot: torch.Size([1, 500, 20])\n",
      "seq: GSTGVTLFVALYDYEARTEDDLSFHKGEKFQILNSSEGDWWEARSLTTGETGYIPSNYVAPVDSIQAEE\n",
      "ang_backbone: torch.Size([1, 500, 3])\n",
      "ang: torch.Size([1, 500, 12])\n",
      "proT5_emb: torch.Size([1, 500, 1024])\n",
      "proT5_mut: torch.Size([1, 500, 1024])\n",
      "seq_mut: 1\n",
      "crd_decoy: torch.Size([1, 41, 4, 3])\n",
      "mask_crd_decoy: torch.Size([1, 41])\n",
      "seq_crd_decoy: 1\n"
     ]
    }
   ],
   "source": [
    "# Add zero padding to the sequence\n",
    "def pad_data(data,max_len=500):\n",
    "    id, crd_backbone, mask, seq_one_hot, seq,ang_backbone, ang,\\\n",
    "                proT5_emb, proT5_mut,seq_mut, crd_decoy, mask_crd_decoy, seq_crd_decoy = data\n",
    "    pad_len = max_len - crd_backbone.shape[1]\n",
    "    crd_backbone = F.pad(crd_backbone,(0,0,0,0,0,pad_len))\n",
    "    seq_one_hot = F.pad(seq_one_hot,(0,0,0,pad_len))\n",
    "    proT5_emb = F.pad(proT5_emb,(0,0,0,pad_len))\n",
    "    proT5_mut = F.pad(proT5_mut,(0,0,0,pad_len))\n",
    "    mask = F.pad(mask,(0,pad_len))\n",
    "    ang = F.pad(ang,(0,0,0,pad_len))\n",
    "    ang_backbone = F.pad(ang_backbone,(0,0,0,pad_len))\n",
    "    return (id, crd_backbone, mask, seq_one_hot, seq,ang_backbone, ang,\\\n",
    "                proT5_emb, proT5_mut,seq_mut, crd_decoy, mask_crd_decoy, seq_crd_decoy)\n",
    "                \n",
    "data = pad_data(data)\n",
    "print_shapes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model \n",
    "model.eval()\n",
    "# model.train()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, crd_backbone, mask, seq_one_hot, seq,ang_backbone, ang,\\\n",
    "                proT5_emb, proT5_mut,seq_mut, crd_decoy, mask_crd_decoy, seq_crd_decoy = data\n",
    "            \n",
    "# wild type and mutant type\n",
    "Xjf = crd_backbone.to(device) # wilde type structure folded\n",
    "Xju = torch.clone(Xjf).to(device) # wilde type structure unfolded\n",
    "Xcd = crd_decoy.to(device) # decoy structure\n",
    "\n",
    "# change the decoy len to match the native len\n",
    "if Xcd.shape[1] > Xjf.shape[1]:\n",
    "    Xcd = Xcd[:,:Xjf.shape[1],:,:]\n",
    "    mask_crd_decoy = mask_crd_decoy[:,:Xjf.shape[1]]\n",
    "elif Xcd.shape[1] < Xjf.shape[1]:\n",
    "    # add zeros to the end of the decoy\n",
    "    Xcd = torch.cat((Xcd, torch.zeros(Xjf.shape[0],Xjf.shape[1] - Xcd.shape[1], *Xcd.shape[2:]).to(device)), dim=1)\n",
    "    mask_crd_decoy = torch.cat((mask_crd_decoy, torch.zeros(mask_crd_decoy.shape[0],mask.shape[1] - mask_crd_decoy.shape[1])), dim=1)\n",
    "    \n",
    "# native structure and decoy structure\n",
    "Xd = torch.clone(Xjf).to(device)\n",
    "Xdu = torch.clone(Xjf).to(device)\n",
    "seq_one_hot = seq_one_hot.to(device) # [batch_size,20,seq_len]\n",
    "\n",
    "# create decoy sequence\n",
    "seq_decoy,mask_decoy, proT5_emb_decoy = mix_A_acid(seq_one_hot = seq_one_hot, emb=proT5_emb, mask = mask,val_type='train',device=device)\n",
    "\n",
    "#emb = torch.cat((esm_embed,seq),dim=2)\n",
    "emb = seq_one_hot.to(device)\n",
    "emb_decoy = seq_decoy.to(device)\n",
    "\n",
    "# move proT5_emb to device\n",
    "proT5_emb_decoy, proT5_emb = proT5_emb_decoy.to(device), proT5_emb.to(device)\n",
    "\n",
    "# zero the parameter gradients\n",
    "optimizer.zero_grad()\n",
    "# squeeze the data\n",
    "Xd, Xjf, Xju, Xcd, Xdu = Xd.squeeze(), Xjf.squeeze(), Xju.squeeze(), Xcd.squeeze(), Xdu.squeeze()\n",
    "emb_decoy, emb = emb_decoy.squeeze(), emb.squeeze()\n",
    "mask_decoy, mask, mask_crd_decoy= mask_decoy.squeeze(), mask.squeeze(), mask_crd_decoy.squeeze()\n",
    "proT5_emb_decoy, proT5_emb = proT5_emb_decoy.squeeze(), proT5_emb.squeeze()\n",
    "\n",
    "# get folded graph  \n",
    "Xjf = get_graph(Xjf, emb, proT5_emb, mask)\n",
    "# get unfolded graph\n",
    "Xju = get_unfolded_graph(Xju, emb, proT5_emb, mask)\n",
    "# get decoy graph\n",
    "Xd, Xcd, Xdu = get_graph(Xd, emb_decoy, proT5_emb_decoy, mask_decoy), get_graph(Xcd, emb, proT5_emb, mask_crd_decoy), get_unfolded_graph(Xd, emb_decoy, proT5_emb_decoy, mask_decoy)\n",
    "# create a batch of Xjf,Xkf,Xju,Xku,x_decoy\n",
    "Xjf,Xju,Xd,Xcd,Xdu= Xjf.unsqueeze(0),Xju.unsqueeze(0),Xd.unsqueeze(0), Xcd.unsqueeze(0), Xdu.unsqueeze(0)  \n",
    "X = torch.cat((Xjf,Xju,Xd,Xcd,Xdu),dim=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # half precision validation\n",
    "    with torch.amp.autocast(device_type=\"cuda\", dtype=CFG.precision):\n",
    "        # calculate the energy for the folded unfolded and decoy structure\n",
    "        E = model(X)\n",
    "        Ejf, Eju, Exd, Ecd, Exdu = E[0], E[1], E[2], E[3], E[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-72.092529296875 3.5161330699920654 32.22923278808594 16.937253952026367\n"
     ]
    }
   ],
   "source": [
    "print(Ejf.item(), Eju.item(), Exd.item(), Ecd.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy difference \n",
      "Wild type: 5.723419666290283\n",
      "Mutant: 5.601985931396484\n",
      "Decoy: 21.944183349609375\n",
      "Decoy coordinates: 15.587738037109375\n"
     ]
    }
   ],
   "source": [
    "# calculate the energy difference\n",
    "dE_wildtype = Eju - Ejf\n",
    "dE_mutant = Eku - Ekf\n",
    "dE_decoy = Exd - Ejf\n",
    "dE_coordsDecoy = Ecd - Ejf\n",
    "# print as a table\n",
    "print(\"Energy difference \")\n",
    "print(f\"Wild type: {dE_wildtype.item()}\")\n",
    "print(f\"Mutant: {dE_mutant.item()}\")\n",
    "print(f\"Decoy: {dE_decoy.item()}\")\n",
    "print(f\"Decoy coordinates: {dE_coordsDecoy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = model(X,f_type = 'A_inference')\n",
    "# E = E.squeeze()\n",
    "Ejf, Ekf, Eju, Eku, Exd = E[0], E[1], E[2], E[3], E[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.43651008605957 4.436499118804932 12.033395767211914 12.258563995361328 26.85599136352539\n",
      "Energy difference \n",
      "Wild type: 7.596885681152344\n",
      "Mutant: 7.8220648765563965\n",
      "Decoy: 22.41948127746582\n"
     ]
    }
   ],
   "source": [
    "sum_Ejf, sum_Ekf, sum_Eju, sum_Eku, sum_Exd = (Ejf).sum(), (Ekf).sum(), (Eju).sum(), (Eku).sum(), (Exd).sum()\n",
    "print(sum_Ejf.item(), sum_Ekf.item(), sum_Eju.item(), sum_Eku.item(), sum_Exd.item())\n",
    "# delta E\n",
    "dE_wildtype = sum_Eju - sum_Ejf\n",
    "dE_mutant = sum_Eku - sum_Ekf\n",
    "dE_decoy = sum_Exd - sum_Ejf\n",
    "# print as a table\n",
    "print(\"Energy difference \")\n",
    "print(f\"Wild type: {dE_wildtype.item()}\")\n",
    "print(f\"Mutant: {dE_mutant.item()}\")\n",
    "print(f\"Decoy: {dE_decoy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Categories (x-axis labels)\n",
    "nodes = Ejf.shape[0]\n",
    "categories = np.arange(1, nodes+1)  # Assuming 69 data points\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.hstack((Ejf.detach().cpu().numpy(), Ekf.detach().cpu().numpy(), Eju.detach().cpu().numpy(), Eku.detach().cpu().numpy(), Exd.detach().cpu().numpy()))\n",
    "print(data.shape)\n",
    "\n",
    "# Create the figure\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "# Plot bars for each example with separation\n",
    "bar_width = 0.2\n",
    "plt.bar(categories-bar_width, data[:, 0], color='red', label='Ejf')\n",
    "plt.bar(categories, data[:, 1], color='blue', label='Ekf')\n",
    "# plt.bar(categories+bar_width, data[:, 2], color='green', label='Eju')\n",
    "# plt.bar(categories, data[:, 3], color='orange', label='Eku')\n",
    "# plt.bar(categories, data[:, 4], color='purple', label='Exd')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Set labels, title, and legend\n",
    "plt.xlabel('Amino acid index')\n",
    "plt.ylabel('Energy')\n",
    "# plt.set_title('Amino acid energy contribution')\n",
    "# Specify legend location\n",
    "plt.legend(loc='upper right')\n",
    "# Display the plot\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8296e-10, -7.8275e-15, -2.7039e-13, -4.4312e-08, -3.0443e-07,\n",
       "        -2.2754e-06, -1.7592e-06, -2.6576e-03, -4.0284e-03, -6.1769e-05,\n",
       "        -1.9732e-07, -9.6246e-08, -1.1597e-07], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Eku**2-Ekf**2\n",
    "a[a<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_params = data_params(num_workers =CFG.num_workers, batch_size=CFG.batch_size,cuda=CFG.cuda,constraint=CFG.constraint, debug=CFG.debug,dataset='scn')\n",
    "train_loader, valid_loader,test_loader = fetch_dataloader(data_dir=CFG.data_path, params=d_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validation function\n",
    "def validation(model, dataloader, device,epoch,N,optimizer,val_type = 'robust'):\n",
    "    \"\"\"\n",
    "    Validation function for the model.\n",
    "    \"\"\"\n",
    "    valid_loss = 0\n",
    "    valid_lossd = 0\n",
    "    valid_lossg = 0\n",
    "    valid_lossc = 0\n",
    "    Exd_list = []\n",
    "    Exn_list = []\n",
    "    seq_len = []\n",
    "    lossg_list = []\n",
    "    lossd_list = []\n",
    "    ids_list = []\n",
    "    n_skips = 0\n",
    "    model.eval() # cant use eval because of the loss function calculation\n",
    "    count_equal = 0\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "       # set progress bar description\n",
    "        tepoch.set_description(f\"Validation: Epoch {epoch}\")\n",
    "        for index, data in (enumerate(tepoch)):\n",
    "            # Clean the GPU cache\n",
    "            if(device.type == \"cuda\" or device.type == \"mps\"):    \n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            id, crd_backbone, mask, seq_one_hot, seq,ang_backbone, ang,\\\n",
    "                proT5_emb, proT5_mut,seq_mut, crd_decoy, mask_crd_decoy, seq_crd_decoy = data\n",
    "            \n",
    "            # wild type and mutant type\n",
    "            Xjf = crd_backbone.to(device) # wilde type structure folded\n",
    "            Xkf = torch.clone(Xjf).to(device) # mutant structure folded\n",
    "            Xju = torch.clone(Xjf).to(device) # wilde type structure unfolded\n",
    "            Xku = torch.clone(Xjf).to(device) # mutant structure unfolded\n",
    "            Xcd = crd_decoy.to(device) # decoy structure\n",
    "\n",
    "            # change the decoy len to match the native len\n",
    "            if Xcd.shape[1] > Xjf.shape[1]:\n",
    "                Xcd = Xcd[:,:Xjf.shape[1],:,:]\n",
    "                mask_crd_decoy = mask_crd_decoy[:,:Xjf.shape[1]]\n",
    "            elif Xcd.shape[1] < Xjf.shape[1]:\n",
    "                # add zeros to the end of the decoy\n",
    "                Xcd = torch.cat((Xcd, torch.zeros(Xjf.shape[0],Xjf.shape[1] - Xcd.shape[1], *Xcd.shape[2:]).to(device)), dim=1)\n",
    "                mask_crd_decoy = torch.cat((mask_crd_decoy, torch.zeros(mask_crd_decoy.shape[0],mask.shape[1] - mask_crd_decoy.shape[1])), dim=1)\n",
    "              \n",
    "            # native structure and decoy structure\n",
    "            Xd = torch.clone(Xjf).to(device)\n",
    "            Xdu = torch.clone(Xjf).to(device)\n",
    "            seq_one_hot = seq_one_hot.to(device) # [batch_size,20,seq_len]\n",
    "            \n",
    "            # create decoy sequence\n",
    "            seq_decoy,mask_decoy, proT5_emb_decoy = mix_A_acid(seq_one_hot = seq_one_hot, emb=proT5_emb, mask = mask,val_type='train',device=device)\n",
    "            \n",
    "            if seq_decoy.shape[1] >CFG.seq_len : # if the sequence is too long, skip it(GPU limitation)\n",
    "                n_skips += 1\n",
    "                continue\n",
    "            #emb = torch.cat((esm_embed,seq),dim=2)\n",
    "            emb = seq_one_hot.to(device)\n",
    "            emb_decoy = seq_decoy.to(device)\n",
    "            emb_mut = get_one_hot(seq_mut[0]).to(device)\n",
    "            \n",
    "            # move proT5_emb to device\n",
    "            proT5_mut, proT5_emb_decoy, proT5_emb = proT5_mut.to(device), proT5_emb_decoy.to(device), proT5_emb.to(device)\n",
    "           \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # squeeze the data\n",
    "            Xd, Xjf, Xkf, Xju, Xku, Xcd, Xdu = Xd.squeeze(), Xjf.squeeze(), Xkf.squeeze(), Xju.squeeze(), Xku.squeeze(), Xcd.squeeze(), Xdu.squeeze()\n",
    "            emb_decoy, emb, emb_mut = emb_decoy.squeeze(), emb.squeeze(), emb_mut.squeeze()\n",
    "            mask_decoy, mask, mask_crd_decoy= mask_decoy.squeeze(), mask.squeeze(), mask_crd_decoy.squeeze()\n",
    "            proT5_emb_decoy, proT5_emb, proT5_mut = proT5_emb_decoy.squeeze(), proT5_emb.squeeze(), proT5_mut.squeeze()\n",
    "            \n",
    "            # get folded graph  \n",
    "            Xjf,Xkf = get_graph(Xjf, emb, proT5_emb, mask), get_graph(Xkf, emb_mut, proT5_mut, mask)\n",
    "            # get unfolded graph\n",
    "            Xju,Xku = get_unfolded_graph(Xju, emb, proT5_emb, mask), get_unfolded_graph(Xku, emb_mut, proT5_mut, mask)\n",
    "            # get decoy graph\n",
    "            Xd, Xcd, Xdu = get_graph(Xd, emb_decoy, proT5_emb_decoy, mask_decoy), get_graph(Xcd, emb, proT5_emb, mask_crd_decoy), get_unfolded_graph(Xd, emb_decoy, proT5_emb_decoy, mask_decoy)\n",
    "            # create a batch of Xjf,Xkf,Xju,Xku,x_decoy\n",
    "            Xjf,Xkf,Xju,Xku,Xd,Xcd,Xdu= Xjf.unsqueeze(0),Xkf.unsqueeze(0),Xju.unsqueeze(0),Xku.unsqueeze(0),Xd.unsqueeze(0), Xcd.unsqueeze(0), Xdu.unsqueeze(0)  \n",
    "            X = torch.cat((Xjf,Xkf,Xju,Xku,Xd,Xcd,Xdu),dim=0)\n",
    "            \n",
    "             # half precision validation\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=CFG.precision):\n",
    "                # calculate the energy for the folded unfolded and decoy structure\n",
    "                E = model(X)\n",
    "                Ejf, Ekf, Eju, Eku, Exd, Ecd, Exdu = E[0], E[1], E[2], E[3], E[4], E[5], E[6]\n",
    "                # calculate the loss   \n",
    "                loss ,lossd, lossg,lossc = criterion(Ejf, Ekf, Eju, Eku, Exd, Xjf, Ecd, Exdu, with_grad = False)\n",
    "                \n",
    "            # Add gradient penalty\n",
    "            Ejf_grad = torch.tensor(0.0).to(device)\n",
    "            if CFG.gradient_penalty:\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect( )\n",
    "                # half precision training\n",
    "                with torch.amp.autocast(device_type=\"cuda\", dtype=CFG.precision):\n",
    "                    # calculate the energy for the wild type\n",
    "                    Xjf.requires_grad = True\n",
    "                    Ejf_grad = model(Xjf)[0]\n",
    "                    lossg = gradient_penalty(Xjf, Ejf_grad)\n",
    "                    \n",
    "                loss += lossg # add the gradient penalty to the loss\n",
    "            \n",
    "            valid_loss += loss.item() \n",
    "            valid_lossd += lossd.item()\n",
    "            valid_lossg += lossg.item()\n",
    "            valid_lossc += lossc.item()\n",
    "            # delete all the variables\n",
    "            del Xjf,Xkf,Xju,Xku,Xd,emb_decoy, emb, emb_mut, mask_decoy, mask, proT5_emb_decoy, proT5_emb, proT5_mut, X, E, Ejf, Ekf, Eju, Eku, Exd\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            # update the progress bar\n",
    "            if index % 1000 == 999:\n",
    "                print(f\"Validation loss: {round(valid_loss/(index + 1),2)}, index: {index}, n_skips: {n_skips}\")\n",
    "    return valid_loss/len(dataloader),valid_lossd/len(dataloader),valid_lossg/len(dataloader),valid_lossc/len(dataloader)\n",
    "\n",
    "def gradient_penalty(X_native, E_native):\n",
    "    \"\"\"Implementing the lossg equation:\n",
    "        The gradient of a wild type structure should be close to zero.\n",
    "        Therefore we will add it to the loss as lossg\"\"\"\n",
    "    partial_dx_native = torch.autograd.grad(outputs=E_native, inputs=X_native, grad_outputs=torch.ones_like(E_native),retain_graph = True ,create_graph=True)[0]\n",
    "    part_dx_native_norm = 0.5*torch.norm(partial_dx_native,p=2)**2\n",
    "    lossg = torch.log(part_dx_native_norm+1)\n",
    "    return lossg\n",
    "\n",
    "def criterion(Ejf, Ekf, Eju, Eku, Exd, X_native, Ecd, Exdu, with_grad = True ):\n",
    "    \"\"\"\n",
    "    The loss function for the model corresponds to 3 main losses:\n",
    "    1. lossg: the partial derivative of the energy with respect to the native structure\n",
    "    2. lossd: the energy of the native structure divided by the decoy energy\n",
    "    3. lossc: the energy softplus function for the native and mutant structure(unfolded and folded)\n",
    "    Args:\n",
    "        Ejf (tensor): The energy of the folded native structure\n",
    "        Ekf (tensor): The energy of the folded mutant structure\n",
    "        Eju (tensor): The energy of the unfolded native structure\n",
    "        Eku (tensor): The energy of the unfolded mutant structure\n",
    "        Exd (tensor): The energy of the decoy sequence\n",
    "        Ecd (tensor): The energy of the decoy structure\n",
    "        Exdu (tensor): The energy of the decoy structure unfolded\n",
    "    output:\n",
    "        loss (tensor): The loss of the model\n",
    "        lossd (tensor): The loss of the model due to the energy of the native structure divided by the decoy energy\n",
    "        lossg (tensor): The loss of the model due to the partial derivative of the energy with respect to the native structure\n",
    "        lossc (tensor): The loss of the model due to the energy softplus function for the native and mutant structure(unfolded and folded)\n",
    "    \"\"\"\n",
    "    lossg = gradient_penalty(X_native, Ejf) if with_grad else torch.tensor(0.0).to(Ejf.device)\n",
    "    lossd = lossd_fucntion(Ejf, Exd, Ecd, Exdu, Eju)\n",
    "    lossc = energy_softplus(Ejf, Ekf, Eju, Eku)\n",
    "    \n",
    "    return lossd+lossg+lossc , lossd, lossg, lossc\n",
    "  \n",
    "def lossd_fucntion(Ejf, Exd, Ecd, Exdu, Eju):\n",
    "    \"\"\"Decoy loss:\n",
    "    - the energy of a decoy sequece is greater than the energy of the wild-type structure (Ejf<Exd)\n",
    "    - the energy of a decoy structure is greater than the energy of the wild-type structure (Ejf<Ecd)\n",
    "    - the energy of a folded decoy is greater than the energy of an unfolded decoy (Exdu<Exd)\n",
    "    - the energy of a decoy structure is greater than the energy of the unfolded native structure (Eju<Ecd)\n",
    "    \"\"\"\n",
    "    loss_decoy = lambda x,y: torch.log((x+1) / (y+1) +1)\n",
    "    \n",
    "    return loss_decoy(Ejf, Exd)+loss_decoy(Ejf, Ecd)+loss_decoy(Exdu, Exd)+loss_decoy(Eju, Ecd)\n",
    "\n",
    "# def loss_decoy(E_native,E_decoy,decoy_threshold = CFG.decoy_threshold):\n",
    "#     \"\"\"Decoy loss, the energy of the native structure divided by the decoy energy\"\"\"\n",
    "#     # if E_native * decoy_threshold < E_decoy:\n",
    "#     #     return torch.tensor(0.0).to(E_native.device)\n",
    "#     return torch.log((E_native+1) / (E_decoy+1) +1)\n",
    "\n",
    "def energy_softplus(Ejf, Ekf, Eju, Eku, beta = 1):\n",
    "    \"\"\"Energy softplus,\n",
    "    As we know the energy diffrence between an unfolded protein and folded protein is positive.\n",
    "    Therefore we will add it to the loss as lossc\"\"\"\n",
    "    \n",
    "    folded_threshold = 2 # the ratio between the energy of the folded and unfolded protein should be greater than 2\n",
    "    softplus = lambda x: torch.log(torch.exp(beta*x)+1)/beta\n",
    "    if (Ekf * folded_threshold < Eku and Eku > Ekf):\n",
    "        lossc1 = softplus(-Ekf) \n",
    "    else:\n",
    "        lossc1 = softplus(Ekf-Eku)\n",
    "        \n",
    "    if (Ejf * folded_threshold < Eju and Eju > Ejf):\n",
    "        lossc2 = softplus(-Ejf) \n",
    "    else:\n",
    "        lossc2 = softplus(Ejf-Eju)\n",
    "    # lossd2 = torch.where(lossd2 < 0.05, torch.tensor(0.0).to(lossd2.device), torch.where(lossd2 > 10.0, lossd2/2.0, lossd2))\n",
    "    return lossc1+lossc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: Epoch 1: 100%|██████████| 160/160 [01:15<00:00,  2.12batch/s]\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_lossd, val_lossg, val_lossc = validation(model, valid_loader,CFG.device,epoch, CFG.N, optimizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.523640039563179 0.30641963880043477 7.146786026656628 0.07043438461837435\n"
     ]
    }
   ],
   "source": [
    "print(val_loss, val_lossd, val_lossg, val_lossc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 0.31, memory cached: 0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaharax/.conda/envs/esm2_env/lib/python3.7/site-packages/torch/cuda/memory.py:397: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "memory_allcation = torch.cuda.memory_allocated(device=device)\n",
    "memory_cached = torch.cuda.memory_cached(device=device)\n",
    "print(f\"memory allocated: {round(memory_allcation/1e9,3)}, memory cached: {round(memory_cached/1e9,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 27 13:59:38 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000 Ada Gener...    On | 00000000:81:00.0 Off |                  Off |\n",
      "| 30%   35C    P2               77W / 300W|   1783MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     38832      C   ...rax/.conda/envs/esm2_env/bin/python     1780MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm2_env_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
